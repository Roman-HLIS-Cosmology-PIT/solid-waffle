{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is simply the beginning of pyirc.py that sets up relevant parameters\n",
    "# and reads in configuration settings;  example uses 'example_config_vis'\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import time\n",
    "import re\n",
    "import numpy\n",
    "import pyirc\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class EmptyClass:\n",
    "    pass\n",
    "\n",
    "\n",
    "outstem = \"default_output\"\n",
    "use_cmap = \"gnuplot\"\n",
    "\n",
    "mydet = \"\"\n",
    "lightfiles = []\n",
    "darkfiles = []\n",
    "vislightfiles = []\n",
    "visdarkfiles = []\n",
    "formatpars = 1\n",
    "nx = 32\n",
    "ny = 32\n",
    "tslices = [3, 11, 13, 21]\n",
    "tslicesM2a = []\n",
    "tslicesM2b = []\n",
    "tslicesM3 = []\n",
    "fullref = True\n",
    "sensitivity_spread_cut = 0.1\n",
    "critfrac = 0.75\n",
    "mychar = \"Basic\"\n",
    "hotpix = False\n",
    "ref_for_hotpix_is_autocorr = False\n",
    "hotpix_logtspace = False\n",
    "hotpix_slidemed = False\n",
    "\n",
    "# order parameters\n",
    "s_bfe = 2  # order of BFE parameters\n",
    "p_order = 0  # non-linearity polynomial table coefficients (table at end goes through order p_order)\n",
    "# set to zero to turn this off\n",
    "\n",
    "# Parameters for basic characterization\n",
    "basicpar = EmptyClass()\n",
    "basicpar.epsilon = 0.01\n",
    "basicpar.subtr_corr = True\n",
    "basicpar.noise_corr = True\n",
    "basicpar.reset_frame = 1\n",
    "basicpar.subtr_href = True\n",
    "basicpar.full_corr = True\n",
    "basicpar.leadtrailSub = False\n",
    "basicpar.g_ptile = 75.0\n",
    "basicpar.fullnl = False\n",
    "basicpar.use_allorder = False\n",
    "\n",
    "# Parameters for BFE\n",
    "bfepar = EmptyClass()\n",
    "bfepar.epsilon = 0.01\n",
    "bfepar.treset = basicpar.reset_frame\n",
    "bfepar.blsub = True\n",
    "bfepar.fullnl = False\n",
    "\n",
    "# Plotting parameters\n",
    "narrowfig = False\n",
    "\n",
    "# Read in information\n",
    "config_file = \"../example_config_vis\"\n",
    "with open(config_file) as myf:\n",
    "    content = myf.read().splitlines()\n",
    "is_in_light = is_in_dark = is_in_vislight = is_in_visdark = False\n",
    "maskX = []  # list of regions to mask\n",
    "maskY = []\n",
    "for line in content:\n",
    "    # Cancellations\n",
    "    m = re.search(r\"^[A-Z]+\\:\", line)\n",
    "    if m:\n",
    "        is_in_light = is_in_dark = is_in_vislight = is_in_visdark = False\n",
    "\n",
    "    # Searches for files -- must be first given the structure of this script!\n",
    "    # The visible flats and darks must come after IR flats and darks\n",
    "    if is_in_light:\n",
    "        m = re.search(r\"^\\s*(\\S.*)$\", line)\n",
    "        if m:\n",
    "            lightfiles += [m.group(1)]\n",
    "    if is_in_dark:\n",
    "        m = re.search(r\"^\\s*(\\S.*)$\", line)\n",
    "        if m:\n",
    "            darkfiles += [m.group(1)]\n",
    "    if is_in_vislight:\n",
    "        m = re.search(r\"^\\s*(\\S.*)$\", line)\n",
    "        if m:\n",
    "            vislightfiles += [m.group(1)]\n",
    "    if is_in_visdark:\n",
    "        m = re.search(r\"^\\s*(\\S.*)$\", line)\n",
    "        if m:\n",
    "            visdarkfiles += [m.group(1)]\n",
    "\n",
    "    # -- Keywords go below here --\n",
    "\n",
    "    # Search for outputs\n",
    "    m = re.search(r\"^OUTPUT\\:\\s*(\\S*)\", line)\n",
    "    if m:\n",
    "        outstem = m.group(1)\n",
    "    # Search for input files\n",
    "    m = re.search(r\"^LIGHT\\:\", line)\n",
    "    if m:\n",
    "        is_in_light = True\n",
    "    m = re.search(r\"^DARK\\:\", line)\n",
    "    if m:\n",
    "        is_in_dark = True\n",
    "    m = re.search(r\"^VISLIGHT\\:\", line)\n",
    "    if m:\n",
    "        is_in_vislight = True\n",
    "    m = re.search(r\"^VISDARK\\:\", line)\n",
    "    if m:\n",
    "        is_in_visdark = True\n",
    "\n",
    "    # Format\n",
    "    m = re.search(r\"^FORMAT:\\s*(\\d+)\", line)\n",
    "    if m:\n",
    "        formatpars = int(m.group(1))\n",
    "\n",
    "    # Bin sizes\n",
    "    m = re.search(r\"^NBIN:\\s*(\\d+)\\s+(\\d+)\", line)\n",
    "    if m:\n",
    "        nx = int(m.group(1))\n",
    "        ny = int(m.group(2))\n",
    "\n",
    "    # Characterization type (Basic or Advanced)\n",
    "    m = re.search(r\"^CHAR:\\s*(\\S+)\", line)\n",
    "    if m:\n",
    "        mychar = m.group(1)\n",
    "        if mychar.lower() == \"advanced\":\n",
    "            m = re.search(r\"^CHAR:\\s*(\\S+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\S+)\", line)\n",
    "            if m:\n",
    "                tchar1 = int(m.group(2))\n",
    "                tchar2 = int(m.group(3))\n",
    "                ncycle = int(m.group(4))\n",
    "                ipnltype = m.group(5)\n",
    "            else:\n",
    "                print(\"Error: insufficient arguments: \" + line + \"\\n\")\n",
    "                exit()\n",
    "\n",
    "    # Time slices\n",
    "    m = re.search(r\"^TIME:\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\", line)\n",
    "    if m:\n",
    "        tslices = [int(m.group(x)) for x in range(1, 5)]\n",
    "    m = re.search(r\"^TIME2A:\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\", line)\n",
    "    if m:\n",
    "        tslicesM2a = [int(m.group(x)) for x in range(1, 5)]\n",
    "    m = re.search(r\"^TIME2B:\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\", line)\n",
    "    if m:\n",
    "        tslicesM2b = [int(m.group(x)) for x in range(1, 5)]\n",
    "    m = re.search(r\"^TIME3:\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\", line)\n",
    "    if m:\n",
    "        tslicesM3 = [int(m.group(x)) for x in range(1, 5)]\n",
    "    #\n",
    "    # reference time slice\n",
    "    m = re.search(r\"^TIMEREF:\\s*(\\d+)\", line)\n",
    "    if m:\n",
    "        bfepar.treset = basicpar.reset_frame = int(m.group(1))\n",
    "\n",
    "    # reference pixel subtraction\n",
    "    m = re.search(r\"^REF\\s+OFF\", line)\n",
    "    if m:\n",
    "        fullref = False\n",
    "\n",
    "    # sensitivity spread cut\n",
    "    m = re.search(r\"^SPREAD:\\s*(\\S+)\", line)\n",
    "    if m:\n",
    "        sensitivity_spread_cut = float(m.group(1))\n",
    "\n",
    "    # variance parameters\n",
    "    m = re.search(r\"^QUANTILE:\\s*(\\S+)\", line)\n",
    "    if m:\n",
    "        basicpar.g_ptile = float(m.group(1))\n",
    "    # correlation parameters\n",
    "    m = re.search(r\"^EPSILON:\\s*(\\S+)\", line)\n",
    "    if m:\n",
    "        bfepar.epsilon = basicpar.epsilon = float(m.group(1))\n",
    "    m = re.search(r\"^IPCSUB:\\s*(\\S+)\", line)\n",
    "    if m:\n",
    "        basicpar.leadtrailSub = m.group(1).lower() in [\"true\", \"yes\"]\n",
    "\n",
    "    # Other parameters\n",
    "    m = re.search(r\"^DETECTOR:\\s*(\\S+)\", line)\n",
    "    if m:\n",
    "        mydet = m.group(1)\n",
    "    m = re.search(r\"^COLOR:\\s*(\\S+)\", line)\n",
    "    if m:\n",
    "        use_cmap = m.group(1)\n",
    "\n",
    "    # Classical non-linearity\n",
    "    m = re.search(r\"^NLPOLY:\\s*(\\S+)\\s+(\\S+)\\s+(\\S+)\", line)\n",
    "    if m:\n",
    "        p_order = int(m.group(1))\n",
    "        nlfit_ts = int(m.group(2))\n",
    "        nlfit_te = int(m.group(3))\n",
    "\n",
    "    m = re.search(r\"^FULLNL:\\s*(\\S+)\\s+(\\S+)\\s+(\\S+)\", line)\n",
    "    if m:\n",
    "        basicpar.fullnl = m.group(1).lower() in [\"true\", \"yes\"]\n",
    "        bfepar.fullnl = m.group(2).lower() in [\"true\", \"yes\"]\n",
    "        basicpar.use_allorder = m.group(3).lower() in [\"true\", \"yes\"]\n",
    "\n",
    "    # Hot pixels\n",
    "    # (adu min, adu max, cut stability, cut isolation)\n",
    "    m = re.search(r\"^HOTPIX:\\s*(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\", line)\n",
    "    if m:\n",
    "        hotpix = True\n",
    "        hotpix_ADU_range = [float(m.group(x)) for x in range(1, 5)]\n",
    "    #\n",
    "    # change reference for hot pixels from last point to autocorr\n",
    "    m = re.search(r\"^HOTREF\\s+AUTOCORR\", line)\n",
    "    if m:\n",
    "        ref_for_hotpix_is_autocorr = True\n",
    "    # log spacing for times?\n",
    "    m = re.search(r\"^HOTPIX\\s+LOGTSPACE\", line)\n",
    "    if m:\n",
    "        hotpix_logtspace = True\n",
    "    # sliding median alpha method?\n",
    "    m = re.search(r\"^HOTPIX\\s+SLIDEMED\", line)\n",
    "    if m:\n",
    "        hotpix_slidemed = True\n",
    "\n",
    "    # Mask regions by hand\n",
    "    m = re.search(r\"^MASK:\\s*(\\d+)\\s+(\\d+)\", line)\n",
    "    if m:\n",
    "        maskX = maskX + [int(m.group(1))]\n",
    "        maskY = maskY + [int(m.group(2))]\n",
    "\n",
    "    # Control figures\n",
    "    m = re.search(r\"^NARROWFIG\", line)\n",
    "    if m:\n",
    "        narrowfig = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up array size parameters\n",
    "pyirc.swi.addbfe(s_bfe)\n",
    "pyirc.swi.addhnl(p_order)\n",
    "print(\"Number of output field per superpixel =\", pyirc.swi.N)\n",
    "\n",
    "# Check number of slices available\n",
    "NTMAX = 16384\n",
    "for f in lightfiles + darkfiles:\n",
    "    nt = pyirc.get_num_slices(formatpars, f)\n",
    "    if nt < NTMAX:\n",
    "        NTMAX = nt\n",
    "\n",
    "# Copy basicpar parameters to bfebar\n",
    "bfepar.use_allorder = basicpar.use_allorder\n",
    "\n",
    "print(\"Output will be directed to {:s}*\".format(outstem))\n",
    "print(\"Light files:\", lightfiles)\n",
    "print(\"Dark files:\", darkfiles)\n",
    "print(\"Visible light files:\", vislightfiles)\n",
    "print('\"Visible\" dark files:', visdarkfiles)\n",
    "print(\"Time slices:\", tslices, \"max=\", NTMAX)\n",
    "print(\"Mask regions:\", maskX, maskY)\n",
    "#\n",
    "if len(lightfiles) != len(darkfiles) or len(lightfiles) < 2:\n",
    "    print(\"Failed: {:d} light files and {:d} dark files\".format(len(lightfiles), len(darkfiles)))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De-bugging pyirc stuff;  doesn't need to be run anymore\n",
    "# gives an idea of how the\n",
    "def get_nside(formatpars):\n",
    "    if formatpars == 1:\n",
    "        return 4096\n",
    "    if formatpars == 2:\n",
    "        return 2048\n",
    "    if formatpars == 3:\n",
    "        return 4096\n",
    "    if formatpars == 4:\n",
    "        return 4096\n",
    "\n",
    "\n",
    "import fitsio\n",
    "\n",
    "filename = (\n",
    "    \"/fs/scratch/PCON0003/cond0007/SCA20829-qy/20191016_95K_1p1m0p1_q_yield_1400nm_gr3_filt4_20829_001.fits\"\n",
    ")\n",
    "formatpars = 4\n",
    "xyrange = [0, 4, 0, 128]\n",
    "tslices = [1, 3, 4, 6]\n",
    "# Recommended True (False defaults to astropy tools, which work but are slow because of the way this script works)\n",
    "use_fitsio = True\n",
    "\n",
    "# Get dimensions of output cube\n",
    "nxuse = xyrange[1] - xyrange[0]\n",
    "nyuse = xyrange[3] - xyrange[2]\n",
    "ntslice_use = len(tslices)\n",
    "output_cube = numpy.zeros((ntslice_use, nyuse, nxuse))\n",
    "print(ntslice_use, nyuse, nxuse)\n",
    "fileh = fitsio.FITS(filename)\n",
    "# Is there no time slice 13??\n",
    "N = get_nside(formatpars)\n",
    "for ts in range(ntslice_use):\n",
    "    t = tslices[ts]\n",
    "    # print(t)\n",
    "    output_cube[ts, :, :] = numpy.array(fileh[1][0, t - 1, xyrange[2] : xyrange[3], xyrange[0] : xyrange[1]])\n",
    "fileh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional parameters\n",
    "# Size of a block\n",
    "N = pyirc.get_nside(formatpars)\n",
    "# Side lengths\n",
    "dx = N // nx\n",
    "dy = N // ny\n",
    "# Pixels in a block\n",
    "npix = dx * dy\n",
    "\n",
    "# Make table of reference pixel corrections for Method 1\n",
    "# This is only happening now on the visible files\n",
    "if fullref:\n",
    "    lightref = pyirc.ref_array(vislightfiles, formatpars, ny, tslices, False)\n",
    "    darkref = pyirc.ref_array(vislightfiles, formatpars, ny, tslices, False)\n",
    "else:\n",
    "    lightref = numpy.zeros((len(vislightfiles), ny, 2 * len(tslices) + 1))\n",
    "    darkref = numpy.zeros((len(visdarkfiles), ny, 2 * len(tslices) + 1))\n",
    "basicpar.subtr_href = fullref\n",
    "\n",
    "# more allocations\n",
    "my_dim = pyirc.swi.N\n",
    "full_info = numpy.zeros((ny, nx, my_dim))\n",
    "is_good = numpy.zeros((ny, nx))\n",
    "\n",
    "if p_order > 0:\n",
    "    # now coefficients for the info table\n",
    "    # note that in 'abs' mode, the full_info[:,:,0] grid is not actually used, it\n",
    "    #   is just there for consistency of the format\n",
    "    # I moved this up here since we want to have these coefficients before the main program runs\n",
    "    nlcubeX, nlfitX, nlderX, pcoefX = pyirc.gen_nl_cube(\n",
    "        vislightfiles,\n",
    "        formatpars,\n",
    "        [basicpar.reset_frame, nlfit_ts, nlfit_te],\n",
    "        [ny, nx],\n",
    "        full_info[:, :, 0],\n",
    "        \"abs\",\n",
    "        False,\n",
    "    )\n",
    "    # fill in\n",
    "    for iy in range(ny):\n",
    "        for ix in range(nx):\n",
    "            if pcoefX[1, iy, ix] != 0:\n",
    "                full_info[iy, ix, pyirc.swi.Nbb] = -pcoefX[0, iy, ix] / pcoefX[1, iy, ix]\n",
    "                for o in range(2, pyirc.swi.p + 1):\n",
    "                    full_info[iy, ix, pyirc.swi.Nbb + o - 1] = pcoefX[o, iy, ix] / pcoefX[1, iy, ix] ** o\n",
    "            else:\n",
    "                full_info[iy, ix, pyirc.swi.Nbb] = -1e49  # error code\n",
    "\n",
    "# Detector characterization data in a cube (basic characterization + BFE Method 1)\n",
    "# Stdout calls are a progress indicator\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function that will take the correlation function bits out of pyirc.basic\n",
    "# It is called corr_5x5 in pyirc.py\n",
    "def corr(region_cube, dark_cube, tslices, lightref, darkref, ctrl_pars, verbose):\n",
    "    # Extract basic parameters\n",
    "    num_files = region_cube.shape[0] - 1\n",
    "    nt = region_cube.shape[1]\n",
    "    dy = region_cube.shape[2]\n",
    "    dx = region_cube.shape[3]\n",
    "    npix = dx * dy\n",
    "    print(num_files)\n",
    "    # Get means and variances at the early and last slices\n",
    "    # region cube is 4D array of dimension number of files +1, number tslices, ymax-ymin, xmax-xmin\n",
    "    box1 = region_cube[0:num_files, 0, :, :] - region_cube[0:num_files, 1, :, :]\n",
    "    box2 = region_cube[0:num_files, 0, :, :] - region_cube[0:num_files, -1, :, :]\n",
    "    box2Noise = dark_cube[0:num_files, 0, :, :] - dark_cube[0:num_files, -1, :, :]\n",
    "\n",
    "    # Correlations of neighboring pixels, in DN^2\n",
    "    tCH = tCV = tCD = 0\n",
    "    epsilon = 0.01\n",
    "    corr_mask = region_cube[-1, 0, :, :]\n",
    "    print(corr_mask.shape)\n",
    "    for if1 in range(1, num_files):\n",
    "        for if2 in range(if1):\n",
    "            print(\"if1,if2\", if1, if2)\n",
    "            temp_box = box2[if1, :, :] - box2[if2, :, :]\n",
    "            print(\"temp_box\", temp_box.shape)\n",
    "            nrun = 1  # need to change to allow for noise\n",
    "            for icorr in range(nrun):\n",
    "                # clipping\n",
    "                cmin = pyirc.pyIRC_percentile(temp_box, corr_mask, 100 * epsilon)\n",
    "                cmax = pyirc.pyIRC_percentile(temp_box, corr_mask, 100 * (1 - epsilon))\n",
    "                this_mask = numpy.where(numpy.logical_and(temp_box > cmin, temp_box < cmax), 1, 0) * corr_mask\n",
    "\n",
    "                if numpy.sum(this_mask) < 1:\n",
    "                    return []  # FAIL!\n",
    "                # mean subtraction\n",
    "                # mean_of_temp_box = numpy.sum(temp_box*this_mask)/numpy.sum(this_mask)\n",
    "                # if subtr_corr and newMeanSubMethod: temp_box -= mean_of_temp_box  # figure out corrections later\n",
    "\n",
    "                # Correlations in horizontal and vertical directions\n",
    "                maskCV = numpy.sum(this_mask[:-1, :] * this_mask[1:, :])\n",
    "                # print(\"this_mask\",this_mask)\n",
    "\n",
    "                maskCH = numpy.sum(this_mask[:, :-1] * this_mask[:, 1:])\n",
    "                print(\"maskCH\", maskCH)\n",
    "                maskCV2 = numpy.sum(this_mask[:-2, :] * this_mask[2:, :])\n",
    "                maskCH2 = numpy.sum(this_mask[:, :-2] * this_mask[:, 2:])\n",
    "\n",
    "                CV = numpy.sum(this_mask[:-1, :] * this_mask[1:, :] * temp_box[:-1, :] * temp_box[1:, :])\n",
    "                # CV = numpy.sum(temp_box[:-1,:]*temp_box[1:,:])  # Tests\n",
    "                # print(\"CV\",CV)\n",
    "                CH = numpy.sum(this_mask[:, :-1] * this_mask[:, 1:] * temp_box[:, :-1] * temp_box[:, 1:])\n",
    "                # CH = numpy.sum(temp_box[:,:-1]*temp_box[:,1:])  # Tests\n",
    "                if maskCH < 1 or maskCV < 1:\n",
    "                    return []\n",
    "                CH /= maskCH\n",
    "                CV /= maskCV\n",
    "                # Need to do all the diagonal calculations and\n",
    "                temp_box = box2Noise[if1, :, :] - box2Noise[if2, :, :]\n",
    "                # Then normalize since we're double-counting\n",
    "                print(\"CV\", CV)\n",
    "    return CH, CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing different ways of measuring correlations\n",
    "# (note: something not quite right about the below, needs a check...)\n",
    "import numpy as np\n",
    "\n",
    "## Example 5x5 array (but in reality we'll work with much larger arrays)\n",
    "x = np.arange(25).reshape((5, 5))\n",
    "print(\"Example array:\", x)\n",
    "\n",
    "### We can first measure the vertical correlations by brute force\n",
    "### The first thing to check is correlations separated by two pixels\n",
    "cvx = np.zeros_like(x)\n",
    "for jdx in range(x.shape[1]):\n",
    "    for idx in range(x.shape[0]):\n",
    "        if jdx < 2:\n",
    "            cvx[jdx][idx] = x[jdx, idx] * x[jdx + 2, idx]\n",
    "        elif (jdx >= 2) & (jdx < x.shape[1] - 2):\n",
    "            cvx[jdx][idx] = x[jdx, idx] * x[jdx + 2, idx] + x[jdx - 2, idx] * x[jdx, idx]\n",
    "        else:\n",
    "            cvx[jdx][idx] = x[jdx - 2, idx] * x[jdx, idx]\n",
    "# print(cvx)\n",
    "print(\"Brute force correlations:\", np.sum(cvx) / 2.0)\n",
    "print(\"Compare to what is called like in pyirc.basic:\", np.sum(x[:-2, :] * x[2:, :]))\n",
    "\n",
    "### Same exercise can be done for the horizontal correlations\n",
    "### Also separated by two pixels\n",
    "# This is currently written differently than above\n",
    "chx = np.zeros_like(x)\n",
    "for jdx in range(x.shape[1]):\n",
    "    for idx in range(x.shape[0] - 2):\n",
    "        chx[jdx][idx] = x[jdx, idx] * x[jdx, idx + 2]\n",
    "# print(chx)\n",
    "print(np.sum(chx))\n",
    "print(\"Compare to:\", np.sum(x[:, :-2] * x[:, 2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Visualization of what's in region_cube\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#print(region_cube.shape)\n",
    "plt.imshow(region_cube[0,0,:,:], origin='lower left')\n",
    "print(region_cube[0,0,:,:].min(), region_cube[0,0,:,:].max())\n",
    "print(region_cube[1,0,:,:].min(), region_cube[1,0,:,:].max())\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests with convolve2d\n",
    "from scipy.signal import convolve2d, correlate2d\n",
    "\n",
    "# If we define an x_flip[j,i]=f[Ny-1-j,Nx-1-i]\n",
    "# then convolve2d between x and x_flip we should get the correlation\n",
    "# Looks like correlated2d maybe does this with the flip built in\n",
    "# y = np.arange(36).reshape((6,6))\n",
    "corr2d_answer = correlate2d(x, x, mode=\"same\")\n",
    "\n",
    "Ny = Nx = 5\n",
    "x_flip = np.flip(x)\n",
    "print(x_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks that numpy flip is producing what we want\n",
    "print(x_flip[0, 0])\n",
    "print(x[4, 4])\n",
    "print(x_flip[0, 2])\n",
    "print(x[4, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_answer = convolve2d(x, x_flip)\n",
    "print(\"conv2d:\", conv2d_answer)\n",
    "print(\"corr2d:\", corr2d_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that the correlations as defined in pyirc.basic produces the same vertical and horizontal\n",
    "# correlations\n",
    "print(\"Compare to what is called like in pyirc.basic for CV:\", np.sum(x[:-1, :] * x[1:, :]))\n",
    "print(\"Compare to what is called like in pyirc.basic for CH:\", np.sum(x[:, :-1] * x[:, 1:]))\n",
    "print(\"Compare to what is called like in pyirc.basic for CV 2 pix away:\", np.sum(x[:-2, :] * x[2:, :]))\n",
    "print(\"Compare to what is called like in pyirc.basic for CH 2 pix away:\", np.sum(x[:, :-2] * x[:, 2:]))\n",
    "# Also testing using center/decenter from ftsolve for when the arrays are huge and we need to get the 5x5 array\n",
    "from ftsolve import decenter, center\n",
    "\n",
    "print(decenter(corr2d_answer)[:5, :5])\n",
    "print(center(decenter(corr2d_answer)[:5, :5]))\n",
    "test = 5\n",
    "print(\n",
    "    test // 2\n",
    ")  # same as numpy.floor_divide, might need this for figuring out where the center of the array is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison with what is currently \"corr\" above\n",
    "from ftsolve import decenter, center\n",
    "from scipy.signal import correlate2d\n",
    "\n",
    "\n",
    "def corr_full(region_cube, dark_cube, tslices, lightref, darkref, ctrl_pars, verbose):\n",
    "    # Extract basic parameters\n",
    "    num_files = region_cube.shape[0] - 1\n",
    "    nt = region_cube.shape[1]\n",
    "    dy = region_cube.shape[2]\n",
    "    dx = region_cube.shape[3]\n",
    "    npix = dx * dy\n",
    "    print(num_files)\n",
    "    # Get means and variances at the early and last slices\n",
    "    # region cube is 4D array of dimension number of files +1, number tslices, ymax-ymin, xmax-xmin\n",
    "    box1 = region_cube[0:num_files, 0, :, :] - region_cube[0:num_files, 1, :, :]\n",
    "    box2 = region_cube[0:num_files, 0, :, :] - region_cube[0:num_files, -1, :, :]\n",
    "    box2Noise = dark_cube[0:num_files, 0, :, :] - dark_cube[0:num_files, -1, :, :]\n",
    "\n",
    "    # Correlations of neighboring pixels, in DN^2\n",
    "    tCH = tCV = tCD = 0\n",
    "    epsilon = 0.01\n",
    "    corr_mask = region_cube[-1, 0, :, :]\n",
    "    print(corr_mask.shape)\n",
    "    for if1 in range(1, num_files):\n",
    "        for if2 in range(if1):\n",
    "            print(\"if1,if2\", if1, if2)\n",
    "            temp_box = box2[if1, :, :] - box2[if2, :, :]\n",
    "            print(\"temp_box\", temp_box.shape)\n",
    "            nrun = 1  # need to change to allow for noise\n",
    "            for icorr in range(nrun):\n",
    "                # clipping\n",
    "                cmin = pyirc.pyIRC_percentile(temp_box, corr_mask, 100 * epsilon)\n",
    "                cmax = pyirc.pyIRC_percentile(temp_box, corr_mask, 100 * (1 - epsilon))\n",
    "                this_mask = numpy.where(numpy.logical_and(temp_box > cmin, temp_box < cmax), 1, 0) * corr_mask\n",
    "\n",
    "                if numpy.sum(this_mask) < 1:\n",
    "                    return []  # FAIL!\n",
    "                # mean subtraction\n",
    "                # mean_of_temp_box = numpy.sum(temp_box*this_mask)/numpy.sum(this_mask)\n",
    "                # if subtr_corr and newMeanSubMethod: temp_box -= mean_of_temp_box  # figure out corrections later\n",
    "\n",
    "                # Correlations in all directions\n",
    "                masktmp = correlate2d(this_mask, this_mask, mode=\"same\")\n",
    "                C_all = correlate2d(this_mask * temp_box, this_mask * temp_box, mode=\"same\")\n",
    "\n",
    "                if numpy.any(masktmp < 1):\n",
    "                    return []\n",
    "\n",
    "                C_all /= masktmp\n",
    "\n",
    "                # hard-coded to return only 5x5 arrays\n",
    "                # Find the \"center\" of this array\n",
    "                if dy % 2 == 0:\n",
    "                    c_y = dy // 2\n",
    "                else:\n",
    "                    c_y = dy / 2 - 1\n",
    "                if dx % 2 == 0:\n",
    "                    c_x = dx // 2\n",
    "                else:\n",
    "                    c_x = dx / 2 - 1\n",
    "                Call_5x5 = C_all[c_y - 3 : c_y + 2, c_x - 3 : c_x + 2]\n",
    "                decenter_Call = decenter(Call_5x5)\n",
    "                print(Call_5x5)\n",
    "                # Need to do all the diagonal calculations and\n",
    "                temp_box = box2Noise[if1, :, :] - box2Noise[if2, :, :]\n",
    "                # Then normalize since we're double-counting\n",
    "\n",
    "    return decenter_Call[0, 1], decenter_Call[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "# Tests, only run for single iy, ix for example? i.e. single super-pixel\n",
    "# print ('Method 1, progress of calculation:')\n",
    "# sys.stdout.write('|')\n",
    "for iy in range(ny):\n",
    "    sys.stdout.write(\" \")\n",
    "# print ('| <- 100%')\n",
    "# sys.stdout.write('|')\n",
    "# for iy in range(ny):\n",
    "for i in range(1):\n",
    "    sys.stdout.write(\"*\")\n",
    "    sys.stdout.flush()\n",
    "    for ix in range(1):\n",
    "        # for ix in range(nx):\n",
    "        region_cube = pyirc.pixel_data(\n",
    "            vislightfiles,\n",
    "            formatpars,\n",
    "            [dx * ix, dx * (ix + 1), dy * iy, dy * (iy + 1)],\n",
    "            tslices,\n",
    "            [sensitivity_spread_cut, True],\n",
    "            False,\n",
    "        )\n",
    "        dark_cube = pyirc.pixel_data(\n",
    "            visdarkfiles,\n",
    "            formatpars,\n",
    "            [dx * ix, dx * (ix + 1), dy * iy, dy * (iy + 1)],\n",
    "            tslices,\n",
    "            [sensitivity_spread_cut, False],\n",
    "            False,\n",
    "        )\n",
    "\n",
    "        info = corr(region_cube, dark_cube, tslices, lightref[:, iy, :], darkref[:, iy, :], basicpar, False)\n",
    "        info_comp = corr_full(\n",
    "            region_cube, dark_cube, tslices, lightref[:, iy, :], darkref[:, iy, :], basicpar, False\n",
    "        )\n",
    "        # info = pyirc.basic(region_cube, dark_cube, tslices, lightref[:,iy,:], darkref[:,iy,:], basicpar, False)\n",
    "        print(region_cube.shape)\n",
    "        print(\"returns CH: \", info[0])\n",
    "        print(\"comp to other CH: \", info_comp[0])\n",
    "        print(\"returns CV: \", info[1])\n",
    "        print(\"comp to other CV: \", info_comp[1])\n",
    "        # exit()\n",
    "\n",
    "# print ('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead trail sub tests --- we are going to compare what basic returns with the corr_5x5 function with leadtrailSub = True\n",
    "# Below is the candidate 5x5 corr function\n",
    "import numpy\n",
    "from ftsolve import decenter, center\n",
    "import scipy\n",
    "from scipy.signal import correlate2d\n",
    "import pyirc\n",
    "\n",
    "\n",
    "def corr_5x5(region_cube, dark_cube, tslices, lightref, darkref, ctrl_pars, verbose):\n",
    "    # Settings:\n",
    "    newMeanSubMethod = True  # use False only for test/debug\n",
    "    leadtrailSub = True  # subtract leading & trailing (by +/-4 pix) from horiz & vert correlations\n",
    "\n",
    "    g_ptile = 75.0  # percentile use for inter-quantile range for variance (default: 75, giving standard IQR)\n",
    "\n",
    "    # Extract basic parameters\n",
    "    num_files = region_cube.shape[0] - 1\n",
    "    nt = region_cube.shape[1]\n",
    "    dy = region_cube.shape[2]\n",
    "    dx = region_cube.shape[3]\n",
    "    npix = dx * dy\n",
    "    if nt != len(tslices):\n",
    "        print(\"Error in pyirc.corr_5x5: incompatible number of time slices\")\n",
    "        exit()\n",
    "    if verbose:\n",
    "        print(\"nfiles = \", num_files, \", ntimes = \", nt, \", dx,dy=\", dx, dy)\n",
    "    treset = 0\n",
    "    if hasattr(ctrl_pars, \"reset_frame\"):\n",
    "        treset = ctrl_pars.reset_frame\n",
    "\n",
    "    # First get correlation parameters\n",
    "    epsilon = 0.01\n",
    "    if hasattr(ctrl_pars, \"epsilon\"):\n",
    "        epsilon = ctrl_pars.epsilon\n",
    "    subtr_corr = True\n",
    "    if hasattr(ctrl_pars, \"subtr_corr\"):\n",
    "        subtr_corr = ctrl_pars.subtr_corr\n",
    "    noise_corr = True\n",
    "    if hasattr(ctrl_pars, \"noise_corr\"):\n",
    "        noise_corr = ctrl_pars.noise_corr\n",
    "    if verbose:\n",
    "        print(\"corr pars =\", epsilon, subtr_corr, noise_corr)\n",
    "    #\n",
    "\n",
    "    # Reference pixel subtraction?\n",
    "    subtr_href = True\n",
    "    if hasattr(ctrl_pars, \"subtr_href\"):\n",
    "        subtr_href = ctrl_pars.subtr_href\n",
    "\n",
    "    # lead-trail subtraction for IPC correlations?\n",
    "    if hasattr(ctrl_pars, \"leadtrailSub\"):\n",
    "        leadtrailSub = ctrl_pars.leadtrailSub\n",
    "\n",
    "    # quantile for variance?\n",
    "    if hasattr(ctrl_pars, \"g_ptile\"):\n",
    "        g_ptile = ctrl_pars.g_ptile\n",
    "\n",
    "    # Get means and variances at the early and last slices\n",
    "    # (i.e. 1-point information)\n",
    "    gauss_iqr_in_sigmas = scipy.stats.norm.ppf(g_ptile / 100.0) * 2  # about 1.349 for g_ptile=75.\n",
    "    box1 = region_cube[0:num_files, 0, :, :] - region_cube[0:num_files, 1, :, :]\n",
    "    box2 = region_cube[0:num_files, 0, :, :] - region_cube[0:num_files, -1, :, :]\n",
    "    box2Noise = dark_cube[0:num_files, 0, :, :] - dark_cube[0:num_files, -1, :, :]\n",
    "    #\n",
    "    if subtr_href:\n",
    "        for f in range(num_files):\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"lightref.shape=\",\n",
    "                    lightref.shape,\n",
    "                    \"subtr ->\",\n",
    "                    lightref[f, nt + 1],\n",
    "                    lightref[f, 2 * nt - 1],\n",
    "                    darkref[f, 2 * nt - 1],\n",
    "                )\n",
    "            box1[f, :, :] -= lightref[f, nt + 1]\n",
    "            box2[f, :, :] -= lightref[f, 2 * nt - 1]\n",
    "            box2Noise[f, :, :] -= darkref[f, 2 * nt - 1]\n",
    "    mean1 = numpy.mean(box1, axis=0)\n",
    "    mean2 = numpy.mean(box2, axis=0)\n",
    "    med1 = numpy.median(mean1)\n",
    "    med2 = numpy.median(mean2)\n",
    "    var1 = 0\n",
    "    var2 = 0\n",
    "    corr_mask = region_cube[-1, 0, :, :]\n",
    "\n",
    "    # Correlations of neighboring pixels, in DN^2\n",
    "    #\n",
    "    tCH = tCV = tCD = tCH2 = tCV2 = tCD2 = tCDV = tCDH = 0  # might be able to delete this\n",
    "    C_shift_mean = np.zeros((dy, dx))\n",
    "    tC_all = np.zeros((dy, dx))\n",
    "    for if1 in range(1, num_files):\n",
    "        for if2 in range(if1):\n",
    "            temp_box = box2[if1, :, :] - box2[if2, :, :]\n",
    "\n",
    "            # Run through twice if we have noise, otherwise once\n",
    "            nrun = 2 if noise_corr else 1\n",
    "            for icorr in range(1):\n",
    "                # for icorr in range (nrun):\n",
    "                # clipping\n",
    "                cmin = pyirc.pyIRC_percentile(temp_box, corr_mask, 100 * epsilon)\n",
    "                cmax = pyirc.pyIRC_percentile(temp_box, corr_mask, 100 * (1 - epsilon))\n",
    "                this_mask = numpy.where(numpy.logical_and(temp_box > cmin, temp_box < cmax), 1, 0) * corr_mask\n",
    "                if numpy.sum(this_mask) < 1:\n",
    "                    return []  # FAIL!\n",
    "                # mean subtraction\n",
    "                mean_of_temp_box = numpy.sum(temp_box * this_mask) / numpy.sum(this_mask)\n",
    "                if subtr_corr and newMeanSubMethod:\n",
    "                    temp_box -= mean_of_temp_box\n",
    "\n",
    "                # Correlations in all directions\n",
    "                masktmp = correlate2d(this_mask, this_mask, mode=\"same\")\n",
    "                C_all = correlate2d(this_mask * temp_box, this_mask * temp_box, mode=\"same\")\n",
    "\n",
    "                if numpy.any(masktmp < 1):\n",
    "                    return []\n",
    "\n",
    "                C_all /= masktmp\n",
    "\n",
    "                print(\"leadtrailSub: \", leadtrailSub)\n",
    "                if leadtrailSub:\n",
    "                    C_pos_shift = np.zeros_like(C_all)\n",
    "                    C_neg_shift = np.zeros_like(C_all)\n",
    "                    # C_shift_mean = np.zeros_like(C_all)\n",
    "\n",
    "                    C_pos_shift[:, :-8] = C_all[\n",
    "                        :, 8:\n",
    "                    ]  # values of the correlation matrix 8 columns to the right\n",
    "                    C_neg_shift[:, 8:] = C_all[\n",
    "                        :, :-8\n",
    "                    ]  # values of the correlation matrix 8 columns to the left\n",
    "\n",
    "                    \"\"\"The 8 columns at the right edge just take the negative shift values, \n",
    "             the 8 columns at the left edge just take the positive shift values,\n",
    "             and in the middle the mean of the two shifts is computed:\n",
    "          \"\"\"\n",
    "                    C_shift_mean[:, 8:-8] = np.mean([C_pos_shift[:, 8:-8], C_neg_shift[:, 8:-8]], axis=0)\n",
    "                    C_shift_mean[:, :8] = C_pos_shift[:, :8]\n",
    "                    C_shift_mean[:, -8:] = C_neg_shift[:, -8:]\n",
    "\n",
    "                    C_all = C_all - C_shift_mean\n",
    "\n",
    "                # need to update the lines below to use C_all\n",
    "\n",
    "                \"\"\"\n",
    "        if subtr_corr and not newMeanSubMethod and not leadtrailSub:\n",
    "          CH -= mean_of_temp_box**2\n",
    "          CV -= mean_of_temp_box**2\n",
    "        tCH += CH * (1 if icorr==0 else -1)\n",
    "        tCV += CV * (1 if icorr==0 else -1)\n",
    "        \n",
    "        if subtr_corr and not newMeanSubMethod and not leadtrailSub: CD -= mean_of_temp_box**2\n",
    "        tCD += CD * (1 if icorr==0 else -1)\n",
    "        \"\"\"\n",
    "\n",
    "                tC_all += C_all * (1 if icorr == 0 else -1)\n",
    "                if verbose:\n",
    "                    print(\"pos =\", if1, if2, \"iteration\", icorr, \"cmin,cmax =\", cmin, cmax)\n",
    "                    print(\n",
    "                        \"Mask size\", numpy.sum(this_mask), \"correlations =\", maskCH, maskCV, \"data:\", CH, CV\n",
    "                    )\n",
    "\n",
    "                temp_box = box2Noise[if1, :, :] - box2Noise[if2, :, :]\n",
    "                # end nested for loop\n",
    "                ############### below has been updated\n",
    "    #\n",
    "    # Normalize covariances. Note that taking the difference of 2 frames doubled the covariance\n",
    "    # matrix, so we have introduced cov_clip_corr\n",
    "    xi = scipy.stats.norm.ppf(1 - epsilon)\n",
    "    cov_clip_corr = (\n",
    "        1.0 - numpy.sqrt(2.0 / numpy.pi) * xi * numpy.exp(-xi * xi / 2.0) / (1.0 - 2.0 * epsilon)\n",
    "    ) ** 2\n",
    "    tC_all /= num_files * (num_files - 1) * cov_clip_corr\n",
    "\n",
    "    # Return a 5x5 matrix of the correlations\n",
    "    decenter_tC_all = decenter(tC_all)\n",
    "    # tC_all_5x5 = center(decenter_tC_all[:5,:5])\n",
    "    # Could also just return the tCH and tCV part of tCall while checking this returns what we want\n",
    "    return [\n",
    "        numpy.sum(this_mask),\n",
    "        med2,\n",
    "        var2,\n",
    "        decenter_tC_all[0, 1],\n",
    "        decenter_tC_all[1, 0],\n",
    "        decenter_tC_all[1, 1],\n",
    "    ]  # Need to update this to tC_all\n",
    "\n",
    "\n",
    "# And calling and comparing these two functions for a single super-pixel\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "for iy in range(ny):\n",
    "    sys.stdout.write(\" \")\n",
    "\n",
    "for i in range(1):\n",
    "    # sys.stdout.write('*'); sys.stdout.flush()\n",
    "    for ix in range(1):\n",
    "        # for ix in range(nx):\n",
    "        region_cube = pyirc.pixel_data(\n",
    "            vislightfiles,\n",
    "            formatpars,\n",
    "            [dx * ix, dx * (ix + 1), dy * iy, dy * (iy + 1)],\n",
    "            tslices,\n",
    "            [sensitivity_spread_cut, True],\n",
    "            False,\n",
    "        )\n",
    "        dark_cube = pyirc.pixel_data(\n",
    "            visdarkfiles,\n",
    "            formatpars,\n",
    "            [dx * ix, dx * (ix + 1), dy * iy, dy * (iy + 1)],\n",
    "            tslices,\n",
    "            [sensitivity_spread_cut, False],\n",
    "            False,\n",
    "        )\n",
    "\n",
    "        # info_corr_5x5 = corr_5x5(region_cube, dark_cube, tslices, lightref[:,iy,:], darkref[:,iy,:], basicpar, False)\n",
    "        info = pyirc.basic(\n",
    "            region_cube, dark_cube, tslices, lightref[:, iy, :], darkref[:, iy, :], basicpar, False\n",
    "        )\n",
    "        info_corr_5x5 = pyirc.corr_5x5(\n",
    "            region_cube, dark_cube, tslices, lightref[:, iy, :], darkref[:, iy, :], basicpar, False\n",
    "        )\n",
    "        # print(region_cube.shape)\n",
    "        print(\"returns CH: \", info[3])\n",
    "        print(\"comp to other CH: \", info_corr_5x5[4])\n",
    "        print(\"returns CV: \", info[4])\n",
    "        print(\"comp to other CV: \", info_corr_5x5[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
