{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is simply the beginning of pyirc.py that sets up relevant parameters\n",
    "# and reads in configuration settings;  example uses 'example_config_vis'\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import time\n",
    "import re\n",
    "import numpy\n",
    "import pyirc\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class EmptyClass:\n",
    "  pass\n",
    "\n",
    "outstem = 'default_output'\n",
    "use_cmap = 'gnuplot'\n",
    "\n",
    "mydet = ''\n",
    "lightfiles = []\n",
    "darkfiles = []\n",
    "vislightfiles = []\n",
    "visdarkfiles = []\n",
    "formatpars = 1\n",
    "nx = 32\n",
    "ny = 32\n",
    "tslices = [3,11,13,21]\n",
    "tslicesM2a = []\n",
    "tslicesM2b = []\n",
    "tslicesM3 = []\n",
    "fullref = True\n",
    "sensitivity_spread_cut = .1\n",
    "critfrac = 0.75\n",
    "mychar = 'Basic'\n",
    "hotpix = False\n",
    "ref_for_hotpix_is_autocorr = False\n",
    "hotpix_logtspace = False\n",
    "hotpix_slidemed = False\n",
    "\n",
    "# order parameters\n",
    "s_bfe = 2     # order of BFE parameters\n",
    "p_order = 0   # non-linearity polynomial table coefficients (table at end goes through order p_order)\n",
    "              # set to zero to turn this off\n",
    "\n",
    "# Parameters for basic characterization\n",
    "basicpar = EmptyClass()\n",
    "basicpar.epsilon = .01\n",
    "basicpar.subtr_corr = True\n",
    "basicpar.noise_corr = True\n",
    "basicpar.reset_frame = 1\n",
    "basicpar.subtr_href = True\n",
    "basicpar.full_corr = True\n",
    "basicpar.leadtrailSub = False\n",
    "basicpar.g_ptile = 75.\n",
    "basicpar.fullnl = False\n",
    "basicpar.use_allorder = False\n",
    "\n",
    "# Parameters for BFE\n",
    "bfepar = EmptyClass()\n",
    "bfepar.epsilon = .01\n",
    "bfepar.treset = basicpar.reset_frame\n",
    "bfepar.blsub = True\n",
    "bfepar.fullnl = False\n",
    "\n",
    "# Plotting parameters\n",
    "narrowfig = False\n",
    "\n",
    "# Read in information\n",
    "config_file = '../example_config_vis'\n",
    "with open(config_file) as myf: content = myf.read().splitlines()\n",
    "is_in_light = is_in_dark = is_in_vislight = is_in_visdark = False\n",
    "maskX = [] # list of regions to mask\n",
    "maskY = []\n",
    "for line in content:\n",
    "  # Cancellations\n",
    "  m = re.search(r'^[A-Z]+\\:', line)\n",
    "  if m: is_in_light = is_in_dark = is_in_vislight = is_in_visdark = False\n",
    "\n",
    "  # Searches for files -- must be first given the structure of this script!\n",
    "  # The visible flats and darks must come after IR flats and darks\n",
    "  if is_in_light:\n",
    "    m = re.search(r'^\\s*(\\S.*)$', line)\n",
    "    if m: lightfiles += [m.group(1)]\n",
    "  if is_in_dark:\n",
    "    m = re.search(r'^\\s*(\\S.*)$', line)\n",
    "    if m: darkfiles += [m.group(1)]\n",
    "  if is_in_vislight:\n",
    "    m = re.search(r'^\\s*(\\S.*)$', line)\n",
    "    if m: vislightfiles += [m.group(1)]\n",
    "  if is_in_visdark:\n",
    "    m = re.search(r'^\\s*(\\S.*)$', line)\n",
    "    if m: visdarkfiles += [m.group(1)]\n",
    "        \n",
    "  # -- Keywords go below here --\n",
    "\n",
    "  # Search for outputs\n",
    "  m = re.search(r'^OUTPUT\\:\\s*(\\S*)', line)\n",
    "  if m: outstem = m.group(1)\n",
    "  # Search for input files\n",
    "  m = re.search(r'^LIGHT\\:', line)\n",
    "  if m: is_in_light = True\n",
    "  m = re.search(r'^DARK\\:', line)\n",
    "  if m: is_in_dark = True\n",
    "  m = re.search(r'^VISLIGHT\\:', line)\n",
    "  if m: is_in_vislight = True\n",
    "  m = re.search(r'^VISDARK\\:', line)\n",
    "  if m: is_in_visdark = True\n",
    "\n",
    "  # Format\n",
    "  m = re.search(r'^FORMAT:\\s*(\\d+)', line)\n",
    "  if m: formatpars = int(m.group(1))\n",
    "\n",
    "  # Bin sizes\n",
    "  m = re.search(r'^NBIN:\\s*(\\d+)\\s+(\\d+)', line)\n",
    "  if m:\n",
    "    nx = int(m.group(1))\n",
    "    ny = int(m.group(2))\n",
    "\n",
    "  # Characterization type (Basic or Advanced)\n",
    "  m = re.search(r'^CHAR:\\s*(\\S+)', line)\n",
    "  if m:\n",
    "     mychar = m.group(1)\n",
    "     if mychar.lower()=='advanced':\n",
    "       m = re.search(r'^CHAR:\\s*(\\S+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\S+)', line)\n",
    "       if m:\n",
    "         tchar1 = int(m.group(2))\n",
    "         tchar2 = int(m.group(3))\n",
    "         ncycle = int(m.group(4))\n",
    "         ipnltype = m.group(5)\n",
    "       else:\n",
    "         print ('Error: insufficient arguments: ' + line + '\\n')\n",
    "         exit()\n",
    "\n",
    "  # Time slices\n",
    "  m = re.search(r'^TIME:\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)', line)\n",
    "  if m: tslices = [ int(m.group(x)) for x in range(1,5)]\n",
    "  m = re.search(r'^TIME2A:\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)', line)\n",
    "  if m: tslicesM2a = [ int(m.group(x)) for x in range(1,5)]\n",
    "  m = re.search(r'^TIME2B:\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)', line)\n",
    "  if m: tslicesM2b = [ int(m.group(x)) for x in range(1,5)]\n",
    "  m = re.search(r'^TIME3:\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)', line)\n",
    "  if m: tslicesM3 = [ int(m.group(x)) for x in range(1,5)]\n",
    "  #\n",
    "  # reference time slice\n",
    "  m = re.search(r'^TIMEREF:\\s*(\\d+)', line)\n",
    "  if m: bfepar.treset = basicpar.reset_frame = int(m.group(1))\n",
    "\n",
    "  # reference pixel subtraction\n",
    "  m = re.search(r'^REF\\s+OFF', line)\n",
    "  if m: fullref = False\n",
    "\n",
    "  # sensitivity spread cut\n",
    "  m = re.search(r'^SPREAD:\\s*(\\S+)', line)\n",
    "  if m: sensitivity_spread_cut = float(m.group(1))\n",
    "\n",
    "  # variance parameters\n",
    "  m = re.search(r'^QUANTILE:\\s*(\\S+)', line)\n",
    "  if m: basicpar.g_ptile = float(m.group(1))\n",
    "  # correlation parameters\n",
    "  m = re.search(r'^EPSILON:\\s*(\\S+)', line)\n",
    "  if m: bfepar.epsilon = basicpar.epsilon = float(m.group(1))\n",
    "  m = re.search(r'^IPCSUB:\\s*(\\S+)', line)\n",
    "  if m: basicpar.leadtrailSub = m.group(1).lower() in ['true', 'yes']\n",
    "\n",
    "  # Other parameters\n",
    "  m = re.search(r'^DETECTOR:\\s*(\\S+)', line)\n",
    "  if m: mydet = m.group(1)\n",
    "  m = re.search(r'^COLOR:\\s*(\\S+)', line)\n",
    "  if m: use_cmap = m.group(1)\n",
    "\n",
    "  # Classical non-linearity\n",
    "  m = re.search(r'^NLPOLY:\\s*(\\S+)\\s+(\\S+)\\s+(\\S+)', line)\n",
    "  if m:\n",
    "    p_order = int(m.group(1))\n",
    "    nlfit_ts = int(m.group(2))\n",
    "    nlfit_te = int(m.group(3))\n",
    "\n",
    "  m = re.search(r'^FULLNL:\\s*(\\S+)\\s+(\\S+)\\s+(\\S+)', line)\n",
    "  if m:\n",
    "    basicpar.fullnl = m.group(1).lower() in ['true', 'yes']\n",
    "    bfepar.fullnl = m.group(2).lower() in ['true', 'yes']\n",
    "    basicpar.use_allorder = m.group(3).lower() in ['true', 'yes']\n",
    "\n",
    "  # Hot pixels\n",
    "  # (adu min, adu max, cut stability, cut isolation)\n",
    "  m = re.search(r'^HOTPIX:\\s*(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)', line)\n",
    "  if m:\n",
    "    hotpix = True\n",
    "    hotpix_ADU_range = [ float(m.group(x)) for x in range(1,5)]\n",
    "  #\n",
    "  # change reference for hot pixels from last point to autocorr\n",
    "  m = re.search(r'^HOTREF\\s+AUTOCORR', line)\n",
    "  if m: ref_for_hotpix_is_autocorr = True\n",
    "  # log spacing for times?\n",
    "  m = re.search(r'^HOTPIX\\s+LOGTSPACE', line)\n",
    "  if m: hotpix_logtspace = True\n",
    "  # sliding median alpha method?\n",
    "  m = re.search(r'^HOTPIX\\s+SLIDEMED', line)\n",
    "  if m: hotpix_slidemed = True\n",
    "\n",
    "  # Mask regions by hand\n",
    "  m = re.search(r'^MASK:\\s*(\\d+)\\s+(\\d+)', line)\n",
    "  if m:\n",
    "    maskX = maskX + [int(m.group(1))]\n",
    "    maskY = maskY + [int(m.group(2))]\n",
    "\n",
    "  # Control figures\n",
    "  m = re.search(r'^NARROWFIG', line)\n",
    "  if m: narrowfig = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of output field per superpixel = 36\n",
      "Output will be directed to out/this_det12*\n",
      "Light files: ['/fs/scratch/PCON0003/cond0007/SCA20829-qy/20191016_95K_1p1m0p1_q_yield_1400nm_gr3_filt4_20829_001.fits', '/fs/scratch/PCON0003/cond0007/SCA20829-qy/20191016_95K_1p1m0p1_q_yield_1400nm_gr3_filt4_20829_002.fits']\n",
      "Dark files: ['/fs/scratch/PCON0003/cond0007/SCA20829/20191018_95K_1p1m0p1_ch0_1400nm_gr3_filt5_shutter_closed_20829_001.fits', '/fs/scratch/PCON0003/cond0007/SCA20829/20191018_95K_1p1m0p1_ch0_1400nm_gr3_filt5_shutter_closed_20829_002.fits']\n",
      "Visible light files: ['/fs/scratch/PCON0003/cond0007/SCA20829-qy/20191016_95K_1p1m0p1_q_yield_480nm_gr3_filt6_20829_001.fits', '/fs/scratch/PCON0003/cond0007/SCA20829-qy/20191016_95K_1p1m0p1_q_yield_480nm_gr3_filt6_20829_002.fits']\n",
      "\"Visible\" dark files: ['/fs/scratch/PCON0003/cond0007/SCA20829/20191018_95K_1p1m0p1_ch0_1400nm_gr3_filt5_shutter_closed_20829_001.fits', '/fs/scratch/PCON0003/cond0007/SCA20829/20191018_95K_1p1m0p1_ch0_1400nm_gr3_filt5_shutter_closed_20829_002.fits']\n",
      "Time slices: [1, 3, 4, 7] max= 11\n",
      "Mask regions: [] []\n"
     ]
    }
   ],
   "source": [
    "# set up array size parameters\n",
    "pyirc.swi.addbfe(s_bfe)\n",
    "pyirc.swi.addhnl(p_order)\n",
    "print ('Number of output field per superpixel =', pyirc.swi.N)\n",
    "\n",
    "# Check number of slices available\n",
    "NTMAX = 16384\n",
    "for f in lightfiles+darkfiles:\n",
    "  nt = pyirc.get_num_slices(formatpars, f)\n",
    "  if nt<NTMAX: NTMAX=nt\n",
    "\n",
    "# Copy basicpar parameters to bfebar\n",
    "bfepar.use_allorder = basicpar.use_allorder\n",
    "\n",
    "print ('Output will be directed to {:s}*'.format(outstem))\n",
    "print ('Light files:', lightfiles)\n",
    "print ('Dark files:', darkfiles)\n",
    "print ('Visible light files:', vislightfiles)\n",
    "print ('\"Visible\" dark files:', visdarkfiles)\n",
    "print ('Time slices:', tslices, 'max=',NTMAX)\n",
    "print ('Mask regions:', maskX, maskY)\n",
    "# \n",
    "if len(lightfiles)!=len(darkfiles) or len(lightfiles)<2:\n",
    "  print ('Failed: {:d} light files and {:d} dark files'.format(len(lightfiles), len(darkfiles)))\n",
    "  exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 128 4\n"
     ]
    }
   ],
   "source": [
    "# De-bugging pyirc stuff;  doesn't need to be run anymore\n",
    "# gives an idea of how the \n",
    "def get_nside(formatpars):\n",
    "  if formatpars==1: return 4096\n",
    "  if formatpars==2: return 2048\n",
    "  if formatpars==3: return 4096\n",
    "  if formatpars==4: return 4096\n",
    "\n",
    "import fitsio\n",
    "filename='/fs/scratch/PCON0003/cond0007/SCA20829-qy/20191016_95K_1p1m0p1_q_yield_1400nm_gr3_filt4_20829_001.fits'\n",
    "formatpars=4\n",
    "xyrange=[0, 4, 0, 128]\n",
    "tslices=[1, 3, 4, 6]\n",
    "# Recommended True (False defaults to astropy tools, which work but are slow because of the way this script works)\n",
    "use_fitsio = True\n",
    "\n",
    "# Get dimensions of output cube\n",
    "nxuse = xyrange[1]-xyrange[0]\n",
    "nyuse = xyrange[3]-xyrange[2]\n",
    "ntslice_use = len(tslices)\n",
    "output_cube = numpy.zeros((ntslice_use, nyuse, nxuse))\n",
    "print(ntslice_use, nyuse, nxuse)\n",
    "fileh = fitsio.FITS(filename)\n",
    "# Is there no time slice 13??\n",
    "N = get_nside(formatpars)\n",
    "for ts in range(ntslice_use):\n",
    "    t = tslices[ts]\n",
    "    #print(t)\n",
    "    output_cube[ts,:,:] = numpy.array(fileh[1][0, t-1, xyrange[2]:xyrange[3], xyrange[0]:xyrange[1]])\n",
    "fileh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional parameters\n",
    "# Size of a block\n",
    "N = pyirc.get_nside(formatpars)\n",
    "# Side lengths\n",
    "dx = N//nx\n",
    "dy = N//ny\n",
    "# Pixels in a block\n",
    "npix = dx*dy\n",
    "\n",
    "# Make table of reference pixel corrections for Method 1\n",
    "# This is only happening now on the visible files\n",
    "if fullref:\n",
    "  lightref = pyirc.ref_array(vislightfiles, formatpars, ny, tslices, False)\n",
    "  darkref = pyirc.ref_array(vislightfiles, formatpars, ny, tslices, False)\n",
    "else:\n",
    "  lightref = numpy.zeros((len(vislightfiles), ny, 2*len(tslices)+1))\n",
    "  darkref = numpy.zeros((len(visdarkfiles), ny, 2*len(tslices)+1))\n",
    "basicpar.subtr_href = fullref\n",
    "\n",
    "# more allocations\n",
    "my_dim = pyirc.swi.N\n",
    "full_info = numpy.zeros((ny,nx,my_dim))\n",
    "is_good = numpy.zeros((ny,nx))\n",
    "\n",
    "if p_order>0:\n",
    "  # now coefficients for the info table\n",
    "  # note that in 'abs' mode, the full_info[:,:,0] grid is not actually used, it\n",
    "  #   is just there for consistency of the format\n",
    "  # I moved this up here since we want to have these coefficients before the main program runs\n",
    "  nlcubeX, nlfitX, nlderX, pcoefX = pyirc.gen_nl_cube(\n",
    "          vislightfiles, formatpars, [basicpar.reset_frame, nlfit_ts, nlfit_te], [ny,nx],\n",
    "        full_info[:,:,0], 'abs', False)\n",
    "  # fill in\n",
    "  for iy in range(ny):\n",
    "    for ix in range(nx):\n",
    "      if pcoefX[1,iy,ix]!=0:\n",
    "        full_info[iy,ix,pyirc.swi.Nbb] = -pcoefX[0,iy,ix]/pcoefX[1,iy,ix]\n",
    "        for o in range(2,pyirc.swi.p+1):\n",
    "          full_info[iy,ix,pyirc.swi.Nbb+o-1] = pcoefX[o,iy,ix]/pcoefX[1,iy,ix]**o\n",
    "      else:\n",
    "        full_info[iy,ix,pyirc.swi.Nbb] = -1e49 # error code\n",
    "\n",
    "# Detector characterization data in a cube (basic characterization + BFE Method 1)\n",
    "# Stdout calls are a progress indicator\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function that will take the correlation function bits out of pyirc.basic\n",
    "# It is called corr_5x5 in pyirc.py\n",
    "def corr(region_cube, dark_cube, tslices, lightref, darkref, ctrl_pars, verbose):\n",
    "  # Extract basic parameters\n",
    "  num_files = region_cube.shape[0]-1\n",
    "  nt = region_cube.shape[1]\n",
    "  dy = region_cube.shape[2]\n",
    "  dx = region_cube.shape[3]\n",
    "  npix = dx*dy\n",
    "  print(num_files)\n",
    "  # Get means and variances at the early and last slices\n",
    "  # region cube is 4D array of dimension number of files +1, number tslices, ymax-ymin, xmax-xmin\n",
    "  box1 = region_cube[0:num_files,0,:,:] - region_cube[0:num_files,1,:,:]\n",
    "  box2 = region_cube[0:num_files,0,:,:] - region_cube[0:num_files,-1,:,:]\n",
    "  box2Noise = dark_cube[0:num_files,0,:,:] - dark_cube[0:num_files,-1,:,:]\n",
    "    \n",
    "  # Correlations of neighboring pixels, in DN^2\n",
    "  tCH = tCV = tCD = 0\n",
    "  epsilon=0.01\n",
    "  corr_mask = region_cube[-1,0,:,:]\n",
    "  print(corr_mask.shape)\n",
    "  for if1 in range(1,num_files):\n",
    "    for if2 in range(if1):\n",
    "      print(\"if1,if2\",if1,if2)\n",
    "      temp_box = box2[if1,:,:] - box2[if2,:,:]\n",
    "      print(\"temp_box\",temp_box.shape)\n",
    "      nrun = 1 # need to change to allow for noise\n",
    "      for icorr in range(nrun):\n",
    "        # clipping\n",
    "        cmin = pyirc.pyIRC_percentile(temp_box,corr_mask,100*epsilon)\n",
    "        cmax = pyirc.pyIRC_percentile(temp_box,corr_mask,100*(1-epsilon))\n",
    "        this_mask = numpy.where(numpy.logical_and(temp_box>cmin,temp_box<cmax),\\\n",
    "1,0) * corr_mask\n",
    "\n",
    "        if numpy.sum(this_mask)<1: return [] # FAIL!\n",
    "        # mean subtraction\n",
    "        #mean_of_temp_box = numpy.sum(temp_box*this_mask)/numpy.sum(this_mask)\n",
    "        #if subtr_corr and newMeanSubMethod: temp_box -= mean_of_temp_box  # figure out corrections later\n",
    "\n",
    "        # Correlations in horizontal and vertical directions\n",
    "        maskCV = numpy.sum(this_mask[:-1,:]*this_mask[1:,:])\n",
    "        #print(\"this_mask\",this_mask)\n",
    "\n",
    "        maskCH = numpy.sum(this_mask[:,:-1]*this_mask[:,1:])\n",
    "        print(\"maskCH\",maskCH)\n",
    "        maskCV2 = numpy.sum(this_mask[:-2,:]*this_mask[2:,:])\n",
    "        maskCH2 = numpy.sum(this_mask[:,:-2]*this_mask[:,2:])\n",
    " \n",
    "        CV = numpy.sum(this_mask[:-1,:]*this_mask[1:,:]*temp_box[:-1,:]*temp_box[1:,:])\n",
    "        #CV = numpy.sum(temp_box[:-1,:]*temp_box[1:,:])  # Tests\n",
    "        #print(\"CV\",CV)\n",
    "        CH = numpy.sum(this_mask[:,:-1]*this_mask[:,1:]*temp_box[:,:-1]*temp_box[:,1:])\n",
    "        #CH = numpy.sum(temp_box[:,:-1]*temp_box[:,1:])  # Tests\n",
    "        if maskCH<1 or maskCV<1: return []\n",
    "        CH /= maskCH\n",
    "        CV /= maskCV\n",
    "        # Need to do all the diagonal calculations and \n",
    "        temp_box = box2Noise[if1,:,:] - box2Noise[if2,:,:]\n",
    "        # Then normalize since we're double-counting\n",
    "        print(\"CV\",CV)\n",
    "  return CH, CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example array: [[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]]\n",
      "Brute force correlations: 2065.0\n",
      "Compare to what is called like in pyirc.basic: 2065\n",
      "2905\n",
      "Compare to: 2905\n"
     ]
    }
   ],
   "source": [
    "# Comparing different ways of measuring correlations\n",
    "# (note: something not quite right about the below, needs a check...)\n",
    "import numpy as np\n",
    "## Example 5x5 array (but in reality we'll work with much larger arrays)\n",
    "x = np.arange(25).reshape((5,5))\n",
    "print(\"Example array:\", x)\n",
    "\n",
    "### We can first measure the vertical correlations by brute force\n",
    "### The first thing to check is correlations separated by two pixels\n",
    "cvx = np.zeros_like(x)\n",
    "for jdx in range(x.shape[1]):\n",
    "    for idx in range(x.shape[0]):\n",
    "        if (jdx<2):\n",
    "            cvx[jdx][idx]=x[jdx,idx]*x[jdx+2,idx]\n",
    "        elif (jdx>=2)&(jdx<x.shape[1]-2):\n",
    "            cvx[jdx][idx]=x[jdx,idx]*x[jdx+2,idx]+x[jdx-2,idx]*x[jdx,idx]\n",
    "        else:\n",
    "            cvx[jdx][idx]=x[jdx-2,idx]*x[jdx,idx]\n",
    "#print(cvx)\n",
    "print(\"Brute force correlations:\",np.sum(cvx)/2.)\n",
    "print(\"Compare to what is called like in pyirc.basic:\", np.sum(x[:-2,:]*x[2:,:]))\n",
    "\n",
    "### Same exercise can be done for the horizontal correlations\n",
    "### Also separated by two pixels\n",
    "# This is currently written differently than above\n",
    "chx = np.zeros_like(x)\n",
    "for jdx in range(x.shape[1]):\n",
    "    for idx in range(x.shape[0]-2):\n",
    "        chx[jdx][idx]=x[jdx,idx]*x[jdx,idx+2]\n",
    "#print(chx)\n",
    "print(np.sum(chx))\n",
    "print(\"Compare to:\", np.sum(x[:,:-2]*x[:,2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Visualization of what's in region_cube\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n#print(region_cube.shape)\\nplt.imshow(region_cube[0,0,:,:], origin='lower left')\\nprint(region_cube[0,0,:,:].min(), region_cube[0,0,:,:].max())\\nprint(region_cube[1,0,:,:].min(), region_cube[1,0,:,:].max())\\nplt.show()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Visualization of what's in region_cube\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#print(region_cube.shape)\n",
    "plt.imshow(region_cube[0,0,:,:], origin='lower left')\n",
    "print(region_cube[0,0,:,:].min(), region_cube[0,0,:,:].max())\n",
    "print(region_cube[1,0,:,:].min(), region_cube[1,0,:,:].max())\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24 23 22 21 20]\n",
      " [19 18 17 16 15]\n",
      " [14 13 12 11 10]\n",
      " [ 9  8  7  6  5]\n",
      " [ 4  3  2  1  0]]\n"
     ]
    }
   ],
   "source": [
    "# Tests with convolve2d\n",
    "from scipy.signal import convolve2d, correlate2d\n",
    "# If we define an x_flip[j,i]=f[Ny-1-j,Nx-1-i]\n",
    "# then convolve2d between x and x_flip we should get the correlation\n",
    "# Looks like correlated2d maybe does this with the flip built in\n",
    "#y = np.arange(36).reshape((6,6))\n",
    "corr2d_answer=correlate2d(x,x,mode='same')\n",
    "\n",
    "Ny=Nx=5\n",
    "x_flip = np.flip(x)\n",
    "print(x_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n",
      "22\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# Checks that numpy flip is producing what we want\n",
    "print(x_flip[0,0])\n",
    "print(x[4,4])\n",
    "print(x_flip[0,2])\n",
    "print(x[4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d: [[   0   24   71  140  230  220  191  144   80]\n",
      " [ 120  278  472  700  960  820  652  458  240]\n",
      " [ 335  712 1128 1580 2065 1700 1308  892  455]\n",
      " [ 620 1276 1964 2680 3420 2760 2084 1396  700]\n",
      " [ 950 1920 2905 3900 4900 3900 2905 1920  950]\n",
      " [ 700 1396 2084 2760 3420 2680 1964 1276  620]\n",
      " [ 455  892 1308 1700 2065 1580 1128  712  335]\n",
      " [ 240  458  652  820  960  700  472  278  120]\n",
      " [  80  144  191  220  230  140   71   24    0]]\n",
      "corr2d: [[1128 1580 2065 1700 1308]\n",
      " [1964 2680 3420 2760 2084]\n",
      " [2905 3900 4900 3900 2905]\n",
      " [2084 2760 3420 2680 1964]\n",
      " [1308 1700 2065 1580 1128]]\n"
     ]
    }
   ],
   "source": [
    "conv2d_answer=convolve2d(x,x_flip)\n",
    "print('conv2d:',conv2d_answer)\n",
    "print('corr2d:',corr2d_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare to what is called like in pyirc.basic for CV: 3420\n",
      "Compare to what is called like in pyirc.basic for CH: 3900\n",
      "Compare to what is called like in pyirc.basic for CV 2 pix away: 2065\n",
      "Compare to what is called like in pyirc.basic for CH 2 pix away: 2905\n",
      "[[4900 3900 2905 2905 3900]\n",
      " [3420 2680 1964 2084 2760]\n",
      " [2065 1580 1128 1308 1700]\n",
      " [2065 1700 1308 1128 1580]\n",
      " [3420 2760 2084 1964 2680]]\n",
      "[[1128 1580 2065 1700 1308]\n",
      " [1964 2680 3420 2760 2084]\n",
      " [2905 3900 4900 3900 2905]\n",
      " [2084 2760 3420 2680 1964]\n",
      " [1308 1700 2065 1580 1128]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# We see that the correlations as defined in pyirc.basic produces the same vertical and horizontal\n",
    "# correlations \n",
    "print(\"Compare to what is called like in pyirc.basic for CV:\", np.sum(x[:-1,:]*x[1:,:]))\n",
    "print(\"Compare to what is called like in pyirc.basic for CH:\", np.sum(x[:,:-1]*x[:,1:]))\n",
    "print(\"Compare to what is called like in pyirc.basic for CV 2 pix away:\", np.sum(x[:-2,:]*x[2:,:]))\n",
    "print(\"Compare to what is called like in pyirc.basic for CH 2 pix away:\", np.sum(x[:,:-2]*x[:,2:]))\n",
    "# Also testing using center/decenter from ftsolve for when the arrays are huge and we need to get the 5x5 array\n",
    "from ftsolve import decenter, center\n",
    "print(decenter(corr2d_answer)[:5,:5])\n",
    "print(center(decenter(corr2d_answer)[:5,:5]))\n",
    "test=5\n",
    "print(test//2)  # same as numpy.floor_divide, might need this for figuring out where the center of the array is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison with what is currently \"corr\" above\n",
    "from ftsolve import decenter, center\n",
    "from scipy.signal import correlate2d\n",
    "def corr_full(region_cube, dark_cube, tslices, lightref, darkref, ctrl_pars, verbose):\n",
    "  # Extract basic parameters\n",
    "  num_files = region_cube.shape[0]-1\n",
    "  nt = region_cube.shape[1]\n",
    "  dy = region_cube.shape[2]\n",
    "  dx = region_cube.shape[3]\n",
    "  npix = dx*dy\n",
    "  print(num_files)\n",
    "  # Get means and variances at the early and last slices\n",
    "  # region cube is 4D array of dimension number of files +1, number tslices, ymax-ymin, xmax-xmin\n",
    "  box1 = region_cube[0:num_files,0,:,:] - region_cube[0:num_files,1,:,:]\n",
    "  box2 = region_cube[0:num_files,0,:,:] - region_cube[0:num_files,-1,:,:]\n",
    "  box2Noise = dark_cube[0:num_files,0,:,:] - dark_cube[0:num_files,-1,:,:]\n",
    "    \n",
    "  # Correlations of neighboring pixels, in DN^2\n",
    "  tCH = tCV = tCD = 0\n",
    "  epsilon=0.01\n",
    "  corr_mask = region_cube[-1,0,:,:]\n",
    "  print(corr_mask.shape)\n",
    "  for if1 in range(1,num_files):\n",
    "    for if2 in range(if1):\n",
    "      print(\"if1,if2\",if1,if2)\n",
    "      temp_box = box2[if1,:,:] - box2[if2,:,:]\n",
    "      print(\"temp_box\",temp_box.shape)\n",
    "      nrun = 1 # need to change to allow for noise\n",
    "      for icorr in range(nrun):\n",
    "        # clipping\n",
    "        cmin = pyirc.pyIRC_percentile(temp_box,corr_mask,100*epsilon)\n",
    "        cmax = pyirc.pyIRC_percentile(temp_box,corr_mask,100*(1-epsilon))\n",
    "        this_mask = numpy.where(numpy.logical_and(temp_box>cmin,temp_box<cmax),\\\n",
    "1,0) * corr_mask\n",
    "\n",
    "        if numpy.sum(this_mask)<1: return [] # FAIL!\n",
    "        # mean subtraction\n",
    "        #mean_of_temp_box = numpy.sum(temp_box*this_mask)/numpy.sum(this_mask)\n",
    "        #if subtr_corr and newMeanSubMethod: temp_box -= mean_of_temp_box  # figure out corrections later\n",
    "\n",
    "        # Correlations in all directions\n",
    "        masktmp = correlate2d(this_mask, this_mask,mode='same')\n",
    "        C_all = correlate2d(this_mask*temp_box, this_mask*temp_box, mode='same')\n",
    "\n",
    "        if numpy.any(masktmp<1): return []\n",
    "\n",
    "        C_all /= masktmp\n",
    "\n",
    "        # hard-coded to return only 5x5 arrays\n",
    "        # Find the \"center\" of this array\n",
    "        if (dy%2==0):\n",
    "            c_y=dy//2\n",
    "        else:\n",
    "            c_y=dy/2 - 1\n",
    "        if (dx%2==0):\n",
    "            c_x=dx//2\n",
    "        else:\n",
    "            c_x=dx/2 - 1\n",
    "        Call_5x5 = C_all[c_y-3:c_y+2,c_x-3:c_x+2]\n",
    "        decenter_Call = decenter(Call_5x5)\n",
    "        print(Call_5x5)\n",
    "        # Need to do all the diagonal calculations and \n",
    "        temp_box = box2Noise[if1,:,:] - box2Noise[if2,:,:]\n",
    "        # Then normalize since we're double-counting\n",
    "\n",
    "  return decenter_Call[0,1], decenter_Call[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                *2\n",
      "(32, 32)\n",
      "if1,if2 1 0\n",
      "temp_box (32, 32)\n",
      "maskCH 724.0\n",
      "CV 50.24209078404402\n",
      "2\n",
      "(32, 32)\n",
      "if1,if2 1 0\n",
      "temp_box (32, 32)\n",
      "[[ 35.16666667  91.45185185  54.23428571  44.36632201  42.44067797]\n",
      " [ 98.47102526  48.68857143  50.24209078  59.36324786  -6.07566766]\n",
      " [-18.12338594  14.08701657 775.01173403  14.08701657 -18.12338594]\n",
      " [ -6.07566766  59.36324786  50.24209078  48.68857143  98.47102526]\n",
      " [ 42.44067797  44.36632201  54.23428571  91.45185185  35.16666667]]\n",
      "(3, 4, 32, 32)\n",
      "returns CH:  14.087016574585636\n",
      "comp to other CH:  14.087016574585636\n",
      "returns CV:  50.24209078404402\n",
      "comp to other CV:  50.24209078404402\n"
     ]
    }
   ],
   "source": [
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "# Tests, only run for single iy, ix for example? i.e. single super-pixel\n",
    "#print ('Method 1, progress of calculation:')\n",
    "#sys.stdout.write('|')\n",
    "for iy in range(ny): sys.stdout.write(' ')\n",
    "#print ('| <- 100%')\n",
    "#sys.stdout.write('|')\n",
    "#for iy in range(ny):\n",
    "for i in range(1):\n",
    "  sys.stdout.write('*'); sys.stdout.flush()\n",
    "  for ix in range(1):\n",
    "  #for ix in range(nx):\n",
    "    region_cube = pyirc.pixel_data(vislightfiles, formatpars, [dx*ix, dx*(ix+1), dy*iy, dy*(iy+1)], tslices,\n",
    "                  [sensitivity_spread_cut, True], False)\n",
    "    dark_cube = pyirc.pixel_data(visdarkfiles, formatpars, [dx*ix, dx*(ix+1), dy*iy, dy*(iy+1)], tslices,\n",
    "                  [sensitivity_spread_cut, False], False)\n",
    "    \n",
    "    info = corr(region_cube, dark_cube, tslices, lightref[:,iy,:], darkref[:,iy,:], basicpar, False)\n",
    "    info_comp = corr_full(region_cube, dark_cube, tslices, lightref[:,iy,:], darkref[:,iy,:], basicpar, False)\n",
    "    #info = pyirc.basic(region_cube, dark_cube, tslices, lightref[:,iy,:], darkref[:,iy,:], basicpar, False)\n",
    "    print(region_cube.shape)\n",
    "    print('returns CH: ',info[0])\n",
    "    print('comp to other CH: ',info_comp[0])\n",
    "    print('returns CV: ',info[1])\n",
    "    print('comp to other CV: ',info_comp[1])\n",
    "    #exit()\n",
    "\n",
    "#print ('|')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                leadtrailSub:  True\n",
      "returns CH:  3.2753236289976764\n",
      "comp to other CH:  38.849823689264255\n",
      "returns CV:  -0.023773882187043828\n",
      "comp to other CV:  26.5938571025776\n"
     ]
    }
   ],
   "source": [
    "# Lead trail sub tests --- we are going to compare what basic returns with the corr_5x5 function with leadtrailSub = True\n",
    "# Below is the candidate 5x5 corr function\n",
    "from ftsolve import decenter, center\n",
    "import scipy\n",
    "from scipy.signal import correlate2d\n",
    "def corr_5x5(region_cube, dark_cube, tslices, lightref, darkref, ctrl_pars, verbose):\n",
    "\n",
    "  # Settings:\n",
    "  newMeanSubMethod = True     # use False only for test/debug\n",
    "  leadtrailSub = True         # subtract leading & trailing (by +/-4 pix) from horiz & vert correlations\n",
    "\n",
    "  g_ptile = 75.               # percentile use for inter-quantile range for variance (default: 75, giving standard IQR)\n",
    "\n",
    "  # Extract basic parameters\n",
    "  num_files = region_cube.shape[0]-1\n",
    "  nt = region_cube.shape[1]\n",
    "  dy = region_cube.shape[2]\n",
    "  dx = region_cube.shape[3]\n",
    "  npix = dx*dy\n",
    "  if nt!=len(tslices):\n",
    "    print ('Error in pyirc.corr_5x5: incompatible number of time slices')\n",
    "    exit()\n",
    "  if verbose: print ('nfiles = ',num_files,', ntimes = ',nt,', dx,dy=',dx,dy)\n",
    "  treset = 0\n",
    "  if hasattr(ctrl_pars,'reset_frame'): treset = ctrl_pars.reset_frame\n",
    "\n",
    "  # First get correlation parameters\n",
    "  epsilon = .01\n",
    "  if hasattr(ctrl_pars,'epsilon'): epsilon = ctrl_pars.epsilon\n",
    "  subtr_corr = True\n",
    "  if hasattr(ctrl_pars,'subtr_corr'): subtr_corr = ctrl_pars.subtr_corr\n",
    "  noise_corr = True\n",
    "  if hasattr(ctrl_pars,'noise_corr'): noise_corr = ctrl_pars.noise_corr\n",
    "  if verbose: print ('corr pars =', epsilon, subtr_corr, noise_corr)\n",
    "  #\n",
    "\n",
    "  # Reference pixel subtraction?\n",
    "  subtr_href = True\n",
    "  if hasattr(ctrl_pars,'subtr_href'): subtr_href = ctrl_pars.subtr_href\n",
    "\n",
    "  # lead-trail subtraction for IPC correlations?\n",
    "  if hasattr(ctrl_pars,'leadtrailSub'): leadtrailSub = ctrl_pars.leadtrailSub\n",
    "\n",
    "  # quantile for variance?\n",
    "  if hasattr(ctrl_pars,'g_ptile'): g_ptile = ctrl_pars.g_ptile\n",
    "\n",
    "  # Get means and variances at the early and last slices\n",
    "  # (i.e. 1-point information)\n",
    "  gauss_iqr_in_sigmas = scipy.stats.norm.ppf(g_ptile/100.)*2  # about 1.349 for g_ptile=75.\n",
    "  box1 = region_cube[0:num_files,0,:,:] - region_cube[0:num_files,1,:,:]\n",
    "  box2 = region_cube[0:num_files,0,:,:] - region_cube[0:num_files,-1,:,:]\n",
    "  box2Noise = dark_cube[0:num_files,0,:,:] - dark_cube[0:num_files,-1,:,:]\n",
    "  #\n",
    "  if subtr_href:\n",
    "    for f in range(num_files):\n",
    "      if verbose: print ('lightref.shape=',lightref.shape, 'subtr ->', lightref[f,nt+1], lightref[f,2*nt-1], darkref[f,2*nt-1])\n",
    "      box1[f,:,:] -= lightref[f,nt+1]\n",
    "      box2[f,:,:] -= lightref[f,2*nt-1]\n",
    "      box2Noise[f,:,:] -= darkref[f,2*nt-1]\n",
    "  mean1 = numpy.mean(box1, axis=0)\n",
    "  mean2 = numpy.mean(box2, axis=0)\n",
    "  med1 = numpy.median(mean1)\n",
    "  med2 = numpy.median(mean2)\n",
    "  var1 = 0\n",
    "  var2 = 0\n",
    "  corr_mask = region_cube[-1,0,:,:]\n",
    "\n",
    "  # Correlations of neighboring pixels, in DN^2\n",
    "  #\n",
    "  tCH = tCV = tCD = tCH2 = tCV2 = tCD2 = tCDV = tCDH = 0  #might be able to delete this\n",
    "  C_shift_mean = np.zeros((dy,dx))\n",
    "  tC_all = np.zeros((dy,dx))\n",
    "  for if1 in range(1,num_files):\n",
    "    for if2 in range(if1):\n",
    "      temp_box = box2[if1,:,:] - box2[if2,:,:]\n",
    "\n",
    "      # Run through twice if we have noise, otherwise once\n",
    "      nrun = 2 if noise_corr else 1\n",
    "      for icorr in range(1):\n",
    "      #for icorr in range (nrun):\n",
    "        # clipping\n",
    "        cmin = pyirc.pyIRC_percentile(temp_box,corr_mask,100*epsilon)\n",
    "        cmax = pyirc.pyIRC_percentile(temp_box,corr_mask,100*(1-epsilon))\n",
    "        this_mask = numpy.where(numpy.logical_and(temp_box>cmin,temp_box<cmax),1,0) * corr_mask\n",
    "        if numpy.sum(this_mask)<1: return [] # FAIL!\n",
    "        # mean subtraction\n",
    "        mean_of_temp_box = numpy.sum(temp_box*this_mask)/numpy.sum(this_mask)\n",
    "        if subtr_corr and newMeanSubMethod: temp_box -= mean_of_temp_box\n",
    "\n",
    "        # Correlations in all directions\n",
    "        masktmp = correlate2d(this_mask, this_mask,mode='same')\n",
    "        C_all = correlate2d(this_mask*temp_box, this_mask*temp_box, mode='same')\n",
    "\n",
    "        if numpy.any(masktmp<1): return []\n",
    "\n",
    "        C_all /= masktmp\n",
    "\n",
    "        print(\"leadtrailSub: \",leadtrailSub)\n",
    "        if leadtrailSub:\n",
    "\n",
    "          C_pos_shift = np.zeros_like(C_all)\n",
    "          C_neg_shift = np.zeros_like(C_all)\n",
    "          #C_shift_mean = np.zeros_like(C_all)\n",
    "\n",
    "          C_pos_shift[:,:-8]=C_all[:,8:] #values of the correlation matrix 8 columns to the right\n",
    "          C_neg_shift[:,8:]=C_all[:,:-8] #values of the correlation matrix 8 columns to the left\n",
    "\n",
    "          \"\"\"The 8 columns at the right edge just take the negative shift values, \n",
    "             the 8 columns at the left edge just take the positive shift values,\n",
    "             and in the middle the mean of the two shifts is computed:\n",
    "          \"\"\"\n",
    "          C_shift_mean[:, 8:-8] = np.mean([C_pos_shift[:, 8:-8], C_neg_shift[:, 8:-8]], axis=0)\n",
    "          C_shift_mean[:, :8] = C_pos_shift[:, :8]\n",
    "          C_shift_mean[:, -8:] = C_neg_shift[:, -8:]\n",
    "\n",
    "          C_all = C_all - C_shift_mean\n",
    "\n",
    "        #need to update the lines below to use C_all\n",
    "        \n",
    "        \"\"\"\n",
    "        if subtr_corr and not newMeanSubMethod and not leadtrailSub:\n",
    "          CH -= mean_of_temp_box**2\n",
    "          CV -= mean_of_temp_box**2\n",
    "        tCH += CH * (1 if icorr==0 else -1)\n",
    "        tCV += CV * (1 if icorr==0 else -1)\n",
    "        \n",
    "        if subtr_corr and not newMeanSubMethod and not leadtrailSub: CD -= mean_of_temp_box**2\n",
    "        tCD += CD * (1 if icorr==0 else -1)\n",
    "        \"\"\"\n",
    "        \n",
    "        tC_all += C_all * (1 if icorr==0 else -1)\n",
    "        if verbose:\n",
    "          print ('pos =', if1, if2, 'iteration', icorr, 'cmin,cmax =', cmin, cmax)\n",
    "          print ('Mask size', numpy.sum(this_mask), 'correlations =', maskCH, maskCV, 'data:', CH, CV)\n",
    "\n",
    "        temp_box = box2Noise[if1,:,:] - box2Noise[if2,:,:]\n",
    "        # end nested for loop\n",
    "        ############### below has been updated\n",
    "  #\n",
    "  # Normalize covariances. Note that taking the difference of 2 frames doubled the covariance\n",
    "  # matrix, so we have introduced cov_clip_corr\n",
    "  xi = scipy.stats.norm.ppf(1-epsilon)\n",
    "  cov_clip_corr = (1. - numpy.sqrt(2./numpy.pi)*xi*numpy.exp(-xi*xi/2.)/(1.-2.*epsilon) )**2\n",
    "  tC_all /= num_files*(num_files-1)*cov_clip_corr\n",
    "  \n",
    "  # Return a 5x5 matrix of the correlations\n",
    "  decenter_tC_all = decenter(tC_all)\n",
    "  #tC_all_5x5 = center(decenter_tC_all[:5,:5])\n",
    "  # Could also just return the tCH and tCV part of tCall while checking this returns what we want\n",
    "  return [numpy.sum(this_mask), med2, var2, decenter_tC_all[0,1], decenter_tC_all[1,0], decenter_tC_all[1,1]]  # Need to update this to tC_all\n",
    "\n",
    "# And calling and comparing these two functions for a single super-pixel\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "for iy in range(ny): sys.stdout.write(' ')\n",
    "\n",
    "for i in range(1):\n",
    "  #sys.stdout.write('*'); sys.stdout.flush()\n",
    "  for ix in range(1):\n",
    "  #for ix in range(nx):\n",
    "    region_cube = pyirc.pixel_data(vislightfiles, formatpars, [dx*ix, dx*(ix+1), dy*iy, dy*(iy+1)], tslices,\n",
    "                  [sensitivity_spread_cut, True], False)\n",
    "    dark_cube = pyirc.pixel_data(visdarkfiles, formatpars, [dx*ix, dx*(ix+1), dy*iy, dy*(iy+1)], tslices,\n",
    "                  [sensitivity_spread_cut, False], False)\n",
    "    \n",
    "    info_corr_5x5 = corr_5x5(region_cube, dark_cube, tslices, lightref[:,iy,:], darkref[:,iy,:], basicpar, False)\n",
    "    info = pyirc.basic(region_cube, dark_cube, tslices, lightref[:,iy,:], darkref[:,iy,:], basicpar, False)\n",
    "    #print(region_cube.shape)\n",
    "    print('returns CH: ',info[3])\n",
    "    print('comp to other CH: ',info_corr_5x5[3])\n",
    "    print('returns CV: ',info[4])\n",
    "    print('comp to other CV: ',info_corr_5x5[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
