{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is simply the beginning of pyirc.py that sets up relevant parameters\n",
    "# and reads in configuration settings;  example uses 'example_config_vis'\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import time\n",
    "import re\n",
    "import numpy\n",
    "import pyirc\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class EmptyClass:\n",
    "  pass\n",
    "\n",
    "outstem = 'default_output'\n",
    "use_cmap = 'gnuplot'\n",
    "\n",
    "mydet = ''\n",
    "lightfiles = []\n",
    "darkfiles = []\n",
    "vislightfiles = []\n",
    "visdarkfiles = []\n",
    "formatpars = 1\n",
    "nx = 32\n",
    "ny = 32\n",
    "tslices = [3,11,13,21]\n",
    "tslicesM2a = []\n",
    "tslicesM2b = []\n",
    "tslicesM3 = []\n",
    "fullref = True\n",
    "sensitivity_spread_cut = .1\n",
    "critfrac = 0.75\n",
    "mychar = 'Basic'\n",
    "hotpix = False\n",
    "ref_for_hotpix_is_autocorr = False\n",
    "hotpix_logtspace = False\n",
    "hotpix_slidemed = False\n",
    "\n",
    "# order parameters\n",
    "s_bfe = 2     # order of BFE parameters\n",
    "p_order = 0   # non-linearity polynomial table coefficients (table at end goes through order p_order)\n",
    "              # set to zero to turn this off\n",
    "\n",
    "# Parameters for basic characterization\n",
    "basicpar = EmptyClass()\n",
    "basicpar.epsilon = .01\n",
    "basicpar.subtr_corr = True\n",
    "basicpar.noise_corr = True\n",
    "basicpar.reset_frame = 1\n",
    "basicpar.subtr_href = True\n",
    "basicpar.full_corr = True\n",
    "basicpar.leadtrailSub = False\n",
    "basicpar.g_ptile = 75.\n",
    "basicpar.fullnl = False\n",
    "basicpar.use_allorder = False\n",
    "\n",
    "# Parameters for BFE\n",
    "bfepar = EmptyClass()\n",
    "bfepar.epsilon = .01\n",
    "bfepar.treset = basicpar.reset_frame\n",
    "bfepar.blsub = True\n",
    "bfepar.fullnl = False\n",
    "\n",
    "# Plotting parameters\n",
    "narrowfig = False\n",
    "\n",
    "# Read in information\n",
    "config_file = '../example_config_vis'\n",
    "with open(config_file) as myf: content = myf.read().splitlines()\n",
    "is_in_light = is_in_dark = is_in_vislight = is_in_visdark = False\n",
    "maskX = [] # list of regions to mask\n",
    "maskY = []\n",
    "for line in content:\n",
    "  # Cancellations\n",
    "  m = re.search(r'^[A-Z]+\\:', line)\n",
    "  if m: is_in_light = is_in_dark = is_in_vislight = is_in_visdark = False\n",
    "\n",
    "  # Searches for files -- must be first given the structure of this script!\n",
    "  # The visible flats and darks must come after IR flats and darks\n",
    "  if is_in_light:\n",
    "    m = re.search(r'^\\s*(\\S.*)$', line)\n",
    "    if m: lightfiles += [m.group(1)]\n",
    "  if is_in_dark:\n",
    "    m = re.search(r'^\\s*(\\S.*)$', line)\n",
    "    if m: darkfiles += [m.group(1)]\n",
    "  if is_in_vislight:\n",
    "    m = re.search(r'^\\s*(\\S.*)$', line)\n",
    "    if m: vislightfiles += [m.group(1)]\n",
    "  if is_in_visdark:\n",
    "    m = re.search(r'^\\s*(\\S.*)$', line)\n",
    "    if m: visdarkfiles += [m.group(1)]\n",
    "        \n",
    "  # -- Keywords go below here --\n",
    "\n",
    "  # Search for outputs\n",
    "  m = re.search(r'^OUTPUT\\:\\s*(\\S*)', line)\n",
    "  if m: outstem = m.group(1)\n",
    "  # Search for input files\n",
    "  m = re.search(r'^LIGHT\\:', line)\n",
    "  if m: is_in_light = True\n",
    "  m = re.search(r'^DARK\\:', line)\n",
    "  if m: is_in_dark = True\n",
    "  m = re.search(r'^VISLIGHT\\:', line)\n",
    "  if m: is_in_vislight = True\n",
    "  m = re.search(r'^VISDARK\\:', line)\n",
    "  if m: is_in_visdark = True\n",
    "\n",
    "  # Format\n",
    "  m = re.search(r'^FORMAT:\\s*(\\d+)', line)\n",
    "  if m: formatpars = int(m.group(1))\n",
    "\n",
    "  # Bin sizes\n",
    "  m = re.search(r'^NBIN:\\s*(\\d+)\\s+(\\d+)', line)\n",
    "  if m:\n",
    "    nx = int(m.group(1))\n",
    "    ny = int(m.group(2))\n",
    "\n",
    "  # Characterization type (Basic or Advanced)\n",
    "  m = re.search(r'^CHAR:\\s*(\\S+)', line)\n",
    "  if m:\n",
    "     mychar = m.group(1)\n",
    "     if mychar.lower()=='advanced':\n",
    "       m = re.search(r'^CHAR:\\s*(\\S+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\S+)', line)\n",
    "       if m:\n",
    "         tchar1 = int(m.group(2))\n",
    "         tchar2 = int(m.group(3))\n",
    "         ncycle = int(m.group(4))\n",
    "         ipnltype = m.group(5)\n",
    "       else:\n",
    "         print ('Error: insufficient arguments: ' + line + '\\n')\n",
    "         exit()\n",
    "\n",
    "  # Time slices\n",
    "  m = re.search(r'^TIME:\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)', line)\n",
    "  if m: tslices = [ int(m.group(x)) for x in range(1,5)]\n",
    "  m = re.search(r'^TIME2A:\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)', line)\n",
    "  if m: tslicesM2a = [ int(m.group(x)) for x in range(1,5)]\n",
    "  m = re.search(r'^TIME2B:\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)', line)\n",
    "  if m: tslicesM2b = [ int(m.group(x)) for x in range(1,5)]\n",
    "  m = re.search(r'^TIME3:\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)', line)\n",
    "  if m: tslicesM3 = [ int(m.group(x)) for x in range(1,5)]\n",
    "  #\n",
    "  # reference time slice\n",
    "  m = re.search(r'^TIMEREF:\\s*(\\d+)', line)\n",
    "  if m: bfepar.treset = basicpar.reset_frame = int(m.group(1))\n",
    "\n",
    "  # reference pixel subtraction\n",
    "  m = re.search(r'^REF\\s+OFF', line)\n",
    "  if m: fullref = False\n",
    "\n",
    "  # sensitivity spread cut\n",
    "  m = re.search(r'^SPREAD:\\s*(\\S+)', line)\n",
    "  if m: sensitivity_spread_cut = float(m.group(1))\n",
    "\n",
    "  # variance parameters\n",
    "  m = re.search(r'^QUANTILE:\\s*(\\S+)', line)\n",
    "  if m: basicpar.g_ptile = float(m.group(1))\n",
    "  # correlation parameters\n",
    "  m = re.search(r'^EPSILON:\\s*(\\S+)', line)\n",
    "  if m: bfepar.epsilon = basicpar.epsilon = float(m.group(1))\n",
    "  m = re.search(r'^IPCSUB:\\s*(\\S+)', line)\n",
    "  if m: basicpar.leadtrailSub = m.group(1).lower() in ['true', 'yes']\n",
    "\n",
    "  # Other parameters\n",
    "  m = re.search(r'^DETECTOR:\\s*(\\S+)', line)\n",
    "  if m: mydet = m.group(1)\n",
    "  m = re.search(r'^COLOR:\\s*(\\S+)', line)\n",
    "  if m: use_cmap = m.group(1)\n",
    "\n",
    "  # Classical non-linearity\n",
    "  m = re.search(r'^NLPOLY:\\s*(\\S+)\\s+(\\S+)\\s+(\\S+)', line)\n",
    "  if m:\n",
    "    p_order = int(m.group(1))\n",
    "    nlfit_ts = int(m.group(2))\n",
    "    nlfit_te = int(m.group(3))\n",
    "\n",
    "  m = re.search(r'^FULLNL:\\s*(\\S+)\\s+(\\S+)\\s+(\\S+)', line)\n",
    "  if m:\n",
    "    basicpar.fullnl = m.group(1).lower() in ['true', 'yes']\n",
    "    bfepar.fullnl = m.group(2).lower() in ['true', 'yes']\n",
    "    basicpar.use_allorder = m.group(3).lower() in ['true', 'yes']\n",
    "\n",
    "  # Hot pixels\n",
    "  # (adu min, adu max, cut stability, cut isolation)\n",
    "  m = re.search(r'^HOTPIX:\\s*(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)', line)\n",
    "  if m:\n",
    "    hotpix = True\n",
    "    hotpix_ADU_range = [ float(m.group(x)) for x in range(1,5)]\n",
    "  #\n",
    "  # change reference for hot pixels from last point to autocorr\n",
    "  m = re.search(r'^HOTREF\\s+AUTOCORR', line)\n",
    "  if m: ref_for_hotpix_is_autocorr = True\n",
    "  # log spacing for times?\n",
    "  m = re.search(r'^HOTPIX\\s+LOGTSPACE', line)\n",
    "  if m: hotpix_logtspace = True\n",
    "  # sliding median alpha method?\n",
    "  m = re.search(r'^HOTPIX\\s+SLIDEMED', line)\n",
    "  if m: hotpix_slidemed = True\n",
    "\n",
    "  # Mask regions by hand\n",
    "  m = re.search(r'^MASK:\\s*(\\d+)\\s+(\\d+)', line)\n",
    "  if m:\n",
    "    maskX = maskX + [int(m.group(1))]\n",
    "    maskY = maskY + [int(m.group(2))]\n",
    "\n",
    "  # Control figures\n",
    "  m = re.search(r'^NARROWFIG', line)\n",
    "  if m: narrowfig = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of output field per superpixel = 61\n",
      "Output will be directed to out/this_det12*\n",
      "Light files: ['/fs/scratch/PCON0003/cond0007/SCA20829-qy/20191016_95K_1p1m0p1_q_yield_1400nm_gr3_filt4_20829_001.fits', '/fs/scratch/PCON0003/cond0007/SCA20829-qy/20191016_95K_1p1m0p1_q_yield_1400nm_gr3_filt4_20829_002.fits']\n",
      "Dark files: ['/fs/scratch/PCON0003/cond0007/SCA20829/20191018_95K_1p1m0p1_ch0_1400nm_gr3_filt5_shutter_closed_20829_001.fits', '/fs/scratch/PCON0003/cond0007/SCA20829/20191018_95K_1p1m0p1_ch0_1400nm_gr3_filt5_shutter_closed_20829_002.fits']\n",
      "Visible light files: ['/fs/scratch/PCON0003/cond0007/SCA20829-qy/20191016_95K_1p1m0p1_q_yield_480nm_gr3_filt6_20829_001.fits', '/fs/scratch/PCON0003/cond0007/SCA20829-qy/20191016_95K_1p1m0p1_q_yield_480nm_gr3_filt6_20829_002.fits']\n",
      "\"Visible\" dark files: ['/fs/scratch/PCON0003/cond0007/SCA20829/20191018_95K_1p1m0p1_ch0_1400nm_gr3_filt5_shutter_closed_20829_001.fits', '/fs/scratch/PCON0003/cond0007/SCA20829/20191018_95K_1p1m0p1_ch0_1400nm_gr3_filt5_shutter_closed_20829_002.fits']\n",
      "Time slices: [1, 3, 4, 7] max= 11\n",
      "Mask regions: [] []\n"
     ]
    }
   ],
   "source": [
    "# set up array size parameters\n",
    "pyirc.swi.addbfe(s_bfe)\n",
    "pyirc.swi.addhnl(p_order)\n",
    "print ('Number of output field per superpixel =', pyirc.swi.N)\n",
    "\n",
    "# Check number of slices available\n",
    "NTMAX = 16384\n",
    "for f in lightfiles+darkfiles:\n",
    "  nt = pyirc.get_num_slices(formatpars, f)\n",
    "  if nt<NTMAX: NTMAX=nt\n",
    "\n",
    "# Copy basicpar parameters to bfebar\n",
    "bfepar.use_allorder = basicpar.use_allorder\n",
    "\n",
    "print ('Output will be directed to {:s}*'.format(outstem))\n",
    "print ('Light files:', lightfiles)\n",
    "print ('Dark files:', darkfiles)\n",
    "print ('Visible light files:', vislightfiles)\n",
    "print ('\"Visible\" dark files:', visdarkfiles)\n",
    "print ('Time slices:', tslices, 'max=',NTMAX)\n",
    "print ('Mask regions:', maskX, maskY)\n",
    "# \n",
    "if len(lightfiles)!=len(darkfiles) or len(lightfiles)<2:\n",
    "  print ('Failed: {:d} light files and {:d} dark files'.format(len(lightfiles), len(darkfiles)))\n",
    "  exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 128 4\n"
     ]
    }
   ],
   "source": [
    "# De-bugging pyirc stuff;  doesn't need to be run anymore\n",
    "# gives an idea of how the \n",
    "def get_nside(formatpars):\n",
    "  if formatpars==1: return 4096\n",
    "  if formatpars==2: return 2048\n",
    "  if formatpars==3: return 4096\n",
    "  if formatpars==4: return 4096\n",
    "\n",
    "import fitsio\n",
    "filename='/fs/scratch/PCON0003/cond0007/SCA20829-qy/20191016_95K_1p1m0p1_q_yield_1400nm_gr3_filt4_20829_001.fits'\n",
    "formatpars=4\n",
    "xyrange=[0, 4, 0, 128]\n",
    "tslices=[1, 3, 4, 6]\n",
    "# Recommended True (False defaults to astropy tools, which work but are slow because of the way this script works)\n",
    "use_fitsio = True\n",
    "\n",
    "# Get dimensions of output cube\n",
    "nxuse = xyrange[1]-xyrange[0]\n",
    "nyuse = xyrange[3]-xyrange[2]\n",
    "ntslice_use = len(tslices)\n",
    "output_cube = numpy.zeros((ntslice_use, nyuse, nxuse))\n",
    "print(ntslice_use, nyuse, nxuse)\n",
    "fileh = fitsio.FITS(filename)\n",
    "# Is there no time slice 13??\n",
    "N = get_nside(formatpars)\n",
    "for ts in range(ntslice_use):\n",
    "    t = tslices[ts]\n",
    "    #print(t)\n",
    "    output_cube[ts,:,:] = numpy.array(fileh[1][0, t-1, xyrange[2]:xyrange[3], xyrange[0]:xyrange[1]])\n",
    "fileh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional parameters\n",
    "# Size of a block\n",
    "N = pyirc.get_nside(formatpars)\n",
    "# Side lengths\n",
    "dx = N//nx\n",
    "dy = N//ny\n",
    "# Pixels in a block\n",
    "npix = dx*dy\n",
    "\n",
    "# Make table of reference pixel corrections for Method 1\n",
    "# This is only happening now on the visible files\n",
    "if fullref:\n",
    "  lightref = pyirc.ref_array(vislightfiles, formatpars, ny, tslices, False)\n",
    "  darkref = pyirc.ref_array(vislightfiles, formatpars, ny, tslices, False)\n",
    "else:\n",
    "  lightref = numpy.zeros((len(vislightfiles), ny, 2*len(tslices)+1))\n",
    "  darkref = numpy.zeros((len(visdarkfiles), ny, 2*len(tslices)+1))\n",
    "basicpar.subtr_href = fullref\n",
    "\n",
    "# more allocations\n",
    "my_dim = pyirc.swi.N\n",
    "full_info = numpy.zeros((ny,nx,my_dim))\n",
    "is_good = numpy.zeros((ny,nx))\n",
    "\n",
    "if p_order>0:\n",
    "  # now coefficients for the info table\n",
    "  # note that in 'abs' mode, the full_info[:,:,0] grid is not actually used, it\n",
    "  #   is just there for consistency of the format\n",
    "  # I moved this up here since we want to have these coefficients before the main program runs\n",
    "  nlcubeX, nlfitX, nlderX, pcoefX = pyirc.gen_nl_cube(\n",
    "          vislightfiles, formatpars, [basicpar.reset_frame, nlfit_ts, nlfit_te], [ny,nx],\n",
    "        full_info[:,:,0], 'abs', False)\n",
    "  # fill in\n",
    "  for iy in range(ny):\n",
    "    for ix in range(nx):\n",
    "      if pcoefX[1,iy,ix]!=0:\n",
    "        full_info[iy,ix,pyirc.swi.Nbb] = -pcoefX[0,iy,ix]/pcoefX[1,iy,ix]\n",
    "        for o in range(2,pyirc.swi.p+1):\n",
    "          full_info[iy,ix,pyirc.swi.Nbb+o-1] = pcoefX[o,iy,ix]/pcoefX[1,iy,ix]**o\n",
    "      else:\n",
    "        full_info[iy,ix,pyirc.swi.Nbb] = -1e49 # error code\n",
    "\n",
    "# Detector characterization data in a cube (basic characterization + BFE Method 1)\n",
    "# Stdout calls are a progress indicator\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function that will take the correlation function bits out of pyirc.basic\n",
    "# It is called corr_5x5 in pyirc.py\n",
    "def corr(region_cube, dark_cube, tslices, lightref, darkref, ctrl_pars, verbose):\n",
    "  # Extract basic parameters\n",
    "  num_files = region_cube.shape[0]-1\n",
    "  nt = region_cube.shape[1]\n",
    "  dy = region_cube.shape[2]\n",
    "  dx = region_cube.shape[3]\n",
    "  npix = dx*dy\n",
    "  print(num_files)\n",
    "  # Get means and variances at the early and last slices\n",
    "  # region cube is 4D array of dimension number of files +1, number tslices, ymax-ymin, xmax-xmin\n",
    "  box1 = region_cube[0:num_files,0,:,:] - region_cube[0:num_files,1,:,:]\n",
    "  box2 = region_cube[0:num_files,0,:,:] - region_cube[0:num_files,-1,:,:]\n",
    "  box2Noise = dark_cube[0:num_files,0,:,:] - dark_cube[0:num_files,-1,:,:]\n",
    "    \n",
    "  # Correlations of neighboring pixels, in DN^2\n",
    "  tCH = tCV = tCD = 0\n",
    "  epsilon=0.01\n",
    "  corr_mask = region_cube[-1,0,:,:]\n",
    "  print(corr_mask.shape)\n",
    "  for if1 in range(1,num_files):\n",
    "    for if2 in range(if1):\n",
    "      print(\"if1,if2\",if1,if2)\n",
    "      temp_box = box2[if1,:,:] - box2[if2,:,:]\n",
    "      print(\"temp_box\",temp_box.shape)\n",
    "      nrun = 1 # need to change to allow for noise\n",
    "      for icorr in range(nrun):\n",
    "        # clipping\n",
    "        cmin = pyirc.pyIRC_percentile(temp_box,corr_mask,100*epsilon)\n",
    "        cmax = pyirc.pyIRC_percentile(temp_box,corr_mask,100*(1-epsilon))\n",
    "        this_mask = numpy.where(numpy.logical_and(temp_box>cmin,temp_box<cmax),\\\n",
    "1,0) * corr_mask\n",
    "\n",
    "        if numpy.sum(this_mask)<1: return [] # FAIL!\n",
    "        # mean subtraction\n",
    "        #mean_of_temp_box = numpy.sum(temp_box*this_mask)/numpy.sum(this_mask)\n",
    "        #if subtr_corr and newMeanSubMethod: temp_box -= mean_of_temp_box  # figure out corrections later\n",
    "\n",
    "        # Correlations in horizontal and vertical directions\n",
    "        maskCV = numpy.sum(this_mask[:-1,:]*this_mask[1:,:])\n",
    "        #print(\"this_mask\",this_mask)\n",
    "\n",
    "        maskCH = numpy.sum(this_mask[:,:-1]*this_mask[:,1:])\n",
    "        maskCV2 = numpy.sum(this_mask[:-2,:]*this_mask[2:,:])\n",
    "        maskCH2 = numpy.sum(this_mask[:,:-2]*this_mask[:,2:])\n",
    " \n",
    "        CV = numpy.sum(this_mask[:-1,:]*this_mask[1:,:]*temp_box[:-1,:]*temp_box[1:,:])\n",
    "        #print(\"CV\",CV)\n",
    "        CH = numpy.sum(this_mask[:,:-1]*this_mask[:,1:]*temp_box[:,:-1]*temp_box[:,1:])\n",
    "        if maskCH<1 or maskCV<1: return []\n",
    "        CH /= maskCH\n",
    "        CV /= maskCV\n",
    "        # Need to do all the diagonal calculations and \n",
    "        temp_box = box2Noise[if1,:,:] - box2Noise[if2,:,:]\n",
    "        # Then normalize since we're double-counting\n",
    "        print(\"CV\",CV)\n",
    "  return CH, CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example array: [[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]]\n",
      "Brute force correlations: 2065.0\n",
      "Compare to what is called like in pyirc.basic: 2065\n",
      "2905\n",
      "Compare to: 2905\n"
     ]
    }
   ],
   "source": [
    "# Comparing different ways of measuring correlations\n",
    "# (note: something not quite right about the below, needs a check...)\n",
    "import numpy as np\n",
    "## Example 5x5 array (but in reality we'll work with much larger arrays)\n",
    "x = np.arange(25).reshape((5,5))\n",
    "print(\"Example array:\", x)\n",
    "\n",
    "### We can first measure the vertical correlations by brute force\n",
    "### The first thing to check is correlations separated by two pixels\n",
    "cvx = np.zeros_like(x)\n",
    "for jdx in range(x.shape[1]):\n",
    "    for idx in range(x.shape[0]):\n",
    "        if (jdx<2):\n",
    "            cvx[jdx][idx]=x[jdx,idx]*x[jdx+2,idx]\n",
    "        elif (jdx>=2)&(jdx<x.shape[1]-2):\n",
    "            cvx[jdx][idx]=x[jdx,idx]*x[jdx+2,idx]+x[jdx-2,idx]*x[jdx,idx]\n",
    "        else:\n",
    "            cvx[jdx][idx]=x[jdx-2,idx]*x[jdx,idx]\n",
    "#print(cvx)\n",
    "print(\"Brute force correlations:\",np.sum(cvx)/2.)\n",
    "print(\"Compare to what is called like in pyirc.basic:\", np.sum(x[:-2,:]*x[2:,:]))\n",
    "\n",
    "### Same exercise can be done for the horizontal correlations\n",
    "### Also separated by two pixels\n",
    "# This is currently written differently than above\n",
    "chx = np.zeros_like(x)\n",
    "for jdx in range(x.shape[1]):\n",
    "    for idx in range(x.shape[0]-2):\n",
    "        chx[jdx][idx]=x[jdx,idx]*x[jdx,idx+2]\n",
    "#print(chx)\n",
    "print(np.sum(chx))\n",
    "print(\"Compare to:\", np.sum(x[:,:-2]*x[:,2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                *2\n",
      "(32, 32)\n",
      "if1,if2 1 0\n",
      "temp_box (32, 32)\n",
      "CV 50.24209078404402\n",
      "(3, 4, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "# Tests, only run for single iy, ix for example? i.e. single super-pixel\n",
    "#print ('Method 1, progress of calculation:')\n",
    "#sys.stdout.write('|')\n",
    "for iy in range(ny): sys.stdout.write(' ')\n",
    "#print ('| <- 100%')\n",
    "#sys.stdout.write('|')\n",
    "#for iy in range(ny):\n",
    "for i in range(1):\n",
    "  sys.stdout.write('*'); sys.stdout.flush()\n",
    "  for ix in range(1):\n",
    "  #for ix in range(nx):\n",
    "    region_cube = pyirc.pixel_data(vislightfiles, formatpars, [dx*ix, dx*(ix+1), dy*iy, dy*(iy+1)], tslices,\n",
    "                  [sensitivity_spread_cut, True], False)\n",
    "    dark_cube = pyirc.pixel_data(visdarkfiles, formatpars, [dx*ix, dx*(ix+1), dy*iy, dy*(iy+1)], tslices,\n",
    "                  [sensitivity_spread_cut, False], False)\n",
    "    \n",
    "    info = corr(region_cube, dark_cube, tslices, lightref[:,iy,:], darkref[:,iy,:], basicpar, False)\n",
    "    #info = pyirc.basic(region_cube, dark_cube, tslices, lightref[:,iy,:], darkref[:,iy,:], basicpar, False)\n",
    "    print(region_cube.shape)\n",
    "    #print(info[0])\n",
    "    #print(info[1])\n",
    "    #exit()\n",
    "\n",
    "#print ('|')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n#print(region_cube.shape)\\nplt.imshow(region_cube[0,0,:,:], origin='lower left')\\nprint(region_cube[0,0,:,:].min(), region_cube[0,0,:,:].max())\\nprint(region_cube[1,0,:,:].min(), region_cube[1,0,:,:].max())\\nplt.show()\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Visualization of what's in region_cube\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#print(region_cube.shape)\n",
    "plt.imshow(region_cube[0,0,:,:], origin='lower left')\n",
    "print(region_cube[0,0,:,:].min(), region_cube[0,0,:,:].max())\n",
    "print(region_cube[1,0,:,:].min(), region_cube[1,0,:,:].max())\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24 23 22 21 20]\n",
      " [19 18 17 16 15]\n",
      " [14 13 12 11 10]\n",
      " [ 9  8  7  6  5]\n",
      " [ 4  3  2  1  0]]\n"
     ]
    }
   ],
   "source": [
    "# Tests with convolve2d\n",
    "from scipy.signal import convolve2d, correlate2d\n",
    "# If we define an x_flip[j,i]=f[Ny-1-j,Nx-1-i]\n",
    "# then convolve2d between x and x_flip we should get the correlation\n",
    "# Looks like correlated2d maybe does this with the flip built in\n",
    "corr2d_answer=correlate2d(x,x)\n",
    "\n",
    "Ny=Nx=5\n",
    "x_flip = np.flip(x)\n",
    "print(x_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n",
      "22\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# Checks that numpy flip is producing what we want\n",
    "print(x_flip[0,0])\n",
    "print(x[4,4])\n",
    "print(x_flip[0,2])\n",
    "print(x[4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d: [[   0   24   71  140  230  220  191  144   80]\n",
      " [ 120  278  472  700  960  820  652  458  240]\n",
      " [ 335  712 1128 1580 2065 1700 1308  892  455]\n",
      " [ 620 1276 1964 2680 3420 2760 2084 1396  700]\n",
      " [ 950 1920 2905 3900 4900 3900 2905 1920  950]\n",
      " [ 700 1396 2084 2760 3420 2680 1964 1276  620]\n",
      " [ 455  892 1308 1700 2065 1580 1128  712  335]\n",
      " [ 240  458  652  820  960  700  472  278  120]\n",
      " [  80  144  191  220  230  140   71   24    0]]\n",
      "corr2d: [[   0   24   71  140  230  220  191  144   80]\n",
      " [ 120  278  472  700  960  820  652  458  240]\n",
      " [ 335  712 1128 1580 2065 1700 1308  892  455]\n",
      " [ 620 1276 1964 2680 3420 2760 2084 1396  700]\n",
      " [ 950 1920 2905 3900 4900 3900 2905 1920  950]\n",
      " [ 700 1396 2084 2760 3420 2680 1964 1276  620]\n",
      " [ 455  892 1308 1700 2065 1580 1128  712  335]\n",
      " [ 240  458  652  820  960  700  472  278  120]\n",
      " [  80  144  191  220  230  140   71   24    0]]\n"
     ]
    }
   ],
   "source": [
    "conv2d_answer=convolve2d(x,x_flip)\n",
    "print('conv2d:',conv2d_answer)\n",
    "print('corr2d:',corr2d_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare to what is called like in pyirc.basic: 3420\n",
      "Compare to what is called like in pyirc.basic: 3900\n"
     ]
    }
   ],
   "source": [
    "# We see that the correlations as defined in pyirc.basic produces the same vertical and horizontal\n",
    "# correlations \n",
    "print(\"Compare to what is called like in pyirc.basic for CV:\", np.sum(x[:-1,:]*x[1:,:]))\n",
    "print(\"Compare to what is called like in pyirc.basic for CH:\", np.sum(x[:,:-1]*x[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
