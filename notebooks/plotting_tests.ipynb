{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "ddir = \"/users/PCON0003/cond0088/Projects/detectors/sw_outputs/PaperIV_chargediffusion\"\n",
    "# t='chris_20829vis_test13_visinfo.npy'\n",
    "# t='ami_modmask_20828vis_fid1_visinfo.npy'\n",
    "t = \"ami_modmask_20828vis_fid1_1st2ndflats_visinfo.npy\"\n",
    "data = np.load(os.path.join(ddir, t))\n",
    "\n",
    "\n",
    "def hist_param(dataf, ncol, nx=32, ny=32, nbins=30, figsize=(8, 8)):\n",
    "    # Need to write the bit that takes ncol and associates it to a dictionary with name\n",
    "    # Currently we can reference the information below\n",
    "    param = dataf[:, :, ncol].reshape(ny, nx)\n",
    "    flatparam = param.ravel()  # Fix this (unnecessary)\n",
    "    plt.figure()\n",
    "    plt.hist(flatparam[~np.isnan(flatparam)], nbins)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(param, origin=\"lower\")\n",
    "    plt.colorbar()\n",
    "    return param, flatparam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the ```data``` array is ny * nx * ncol where there are a total of ny * nx superpixels and the ncol are defined below: \n",
    "```\n",
    "# columns  0 .. 24 are the visible BFE kernel in e^-1 (order: dy=-2 dx=-2; dy=-2 dx=-1; dy=-2 dx=0; ...)\n",
    "# columns 25 .. 49 are the visible Phi kernel (order: dy=-2 dx=-2; dy=-2 dx=-1; dy=-2 dx=0; ...)\n",
    "# column 50 is the quantum yield omega parameter\n",
    "# column 51 is Cxx charge diffusion in pixels^2\n",
    "# column 52 is Cxy charge diffusion in pixels^2\n",
    "# column 53 is Cyy charge diffusion in pixels^2\n",
    "# column 54 is visible current Ie (e per frame)\n",
    "# column 55 is number of iterations in p2 kernel\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the omega parameter\n",
    "om = data[:, :, 50]\n",
    "flatom = om.ravel()\n",
    "num_bins = 30\n",
    "# plt.hist(flatom[~np.isnan(flatom)])\n",
    "# Looks like there are some nan values that prevent hist from working automatically\n",
    "plt.hist(flatom, bins=np.linspace(0, 0.1, num=num_bins))\n",
    "plt.xlabel(\"$omega$\")\n",
    "plt.figure()\n",
    "plt.imshow(om, origin=\"lower\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_param(data, 50, nx=32, ny=32, nbins=30, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterations in the p2 kernel\n",
    "nit = data[:, :, 55]\n",
    "flatnit = nit.ravel()\n",
    "num_bins = 30\n",
    "plt.hist(flatnit, bins=np.linspace(0, 100, num=num_bins))\n",
    "plt.xlabel(\"niter\")\n",
    "plt.figure()\n",
    "plt.imshow(nit, origin=\"lower\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge diffusion parameters\n",
    "cxx = data[:, :, 51]\n",
    "cxy = data[:, :, 52]\n",
    "cyy = data[:, :, 53]\n",
    "flatcxx = cxx.ravel()\n",
    "flatcxy = cxy.ravel()\n",
    "flatcyy = cyy.ravel()\n",
    "# There is/are 1 nan vals for cxx and cyy, and 2 for cxy\n",
    "flatcxx_nan = np.isnan(flatcxx)\n",
    "flatcxy_nan = np.isnan(flatcxy)\n",
    "flatcyy_nan = np.isnan(flatcyy)\n",
    "print(flatcxx[flatcxx_nan == True])\n",
    "print(flatcxy[flatcxy_nan == True])\n",
    "print(flatcyy[flatcyy_nan == True])\n",
    "print(flatcxx[flatcxx == 0])\n",
    "plt.imshow(cxx, origin=\"lower\")\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(cxy, origin=\"lower\")\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(cyy, origin=\"lower\")\n",
    "plt.colorbar()\n",
    "\n",
    "# We could also plot the histograms of these to compare the distributions\n",
    "plt.figure()\n",
    "plt.hist(flatcxx[~flatcxx_nan], 30, histtype=\"step\", label=\"cxx\", ls=\"-\")\n",
    "plt.hist(flatcxy[~flatcxy_nan], 30, histtype=\"step\", label=\"cxy\", ls=\":\")\n",
    "plt.hist(flatcyy[~flatcyy_nan], 30, histtype=\"step\", label=\"cyy\", ls=\"-.\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"charge diffusion component in pixels$^2$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function adapted from\n",
    "# https://www.programcreek.com/python/example/61396/matplotlib.patches.Ellipse\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "\n",
    "def plot_cov_ellipse(cov, pos, nstd=1, ax=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots an `nstd` sigma error ellipse based on the specified covariance\n",
    "    matrix (`cov`). Additional keyword arguments are passed on to the\n",
    "    ellipse patch artist.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        cov : The 2x2 covariance matrix to base the ellipse on\n",
    "        pos : The location of the center of the ellipse. Expects a 2-element\n",
    "            sequence of [x0, y0].\n",
    "        nstd : The radius of the ellipse in numbers of standard deviations.\n",
    "            Defaults to 2 standard deviations.\n",
    "        ax : The axis that the ellipse will be plotted on. Defaults to the\n",
    "            current axis.\n",
    "        Additional keyword arguments are pass on to the ellipse patch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A matplotlib ellipse artist\n",
    "    \"\"\"\n",
    "\n",
    "    def eigsorted(cov):\n",
    "        vals, vecs = np.linalg.eigh(cov)\n",
    "        order = vals.argsort()[::-1]\n",
    "        return vals[order], vecs[:, order]\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    vals, vecs = eigsorted(cov)\n",
    "    theta = np.degrees(np.arctan2(*vecs[:, 0][::-1]))\n",
    "\n",
    "    # Width and height are \"full\" widths, not radius\n",
    "    width, height = 2 * nstd * np.sqrt(vals)\n",
    "    ellip = Ellipse(xy=pos, width=width, height=height, angle=theta, **kwargs)\n",
    "\n",
    "    ax.add_artist(ellip)\n",
    "    return ellip\n",
    "\n",
    "\n",
    "# Construct the mean cov\n",
    "pos = [0.5, 0.5]\n",
    "mean_cov = np.zeros((2, 2))\n",
    "mean_cov[0, 0] = np.mean(flatcxx[~flatcxx_nan])\n",
    "mean_cov[1, 0] = mean_cov[0, 1] = np.mean(flatcxy[~flatcxy_nan])\n",
    "mean_cov[1, 1] = np.mean(flatcyy[~flatcyy_nan])\n",
    "fig, axs = plt.subplots(1, 1, figsize=(9, 9))\n",
    "plot_cov_ellipse(mean_cov, pos, nstd=0.1, ax=axs)\n",
    "print(mean_cov)\n",
    "# Grid of covs for each superpixel\n",
    "print(cxx.shape)\n",
    "for idx in range(cxx.shape[0]):\n",
    "    for jdx in range(cxx.shape[1]):\n",
    "        meancov = np.zeros((2, 2))\n",
    "        mean_cov[0, 0] = cxx[jdx][idx]\n",
    "        mean_cov[1, 0] = mean_cov[0, 1] = cxy[jdx][idx]\n",
    "        mean_cov[1, 1] = cyy[jdx][idx]\n",
    "        plot_cov_ellipse(mean_cov, [jdx, idx], nstd=0.8, ax=axs)\n",
    "axs.set_xlim(-1, 32)\n",
    "axs.set_ylim(-1, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the Ie parameter\n",
    "ie = data[:, :, 54]\n",
    "flatie = ie.ravel()\n",
    "num_bins = 30\n",
    "# plt.hist(flatie[~np.isnan(flatie)])\n",
    "# Looks like there are some nan values that prevent hist from working automatically\n",
    "plt.hist(flatie, bins=np.linspace(850, 1100, num=num_bins))\n",
    "plt.xlabel(\"$I_e$\")\n",
    "plt.figure()\n",
    "plt.imshow(ie, origin=\"lower\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at some of Chris's runs with different dimensions of superpixels\n",
    "```grep -r \"NBIN: 128 8\" *config.txt``` from within the directory ```/users/PCON0003/cond0088/Projects/detectors/sw_outputs/PaperIV_chargediffusion``` shows that test14 and test16 both have this configuration of superpixels.  Looks like the difference is that test16 includes a bunch of \"second\" in the sequence flats (and also the results are not available as of Jan 7 4pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test14 = \"chris_20829vis_test14_visinfo.npy\"\n",
    "d_test14 = np.load(os.path.join(ddir, t_test14))\n",
    "# omega\n",
    "om, flatom = hist_param(d_test14, 50, nx=128, ny=8, nbins=30, figsize=(16, 4))\n",
    "# cxx, cxy, cyy\n",
    "cxx, flatcxx = hist_param(d_test14, 51, nx=128, ny=8, figsize=(16, 4))\n",
    "cxy, flatcxy = hist_param(d_test14, 52, nx=128, ny=8, figsize=(16, 4))\n",
    "cyy, flatcyy = hist_param(d_test14, 53, nx=128, ny=8, figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse in one dimension to see if there are any features that stand out\n",
    "\n",
    "plt.plot(om.mean(axis=0))\n",
    "plt.figure()\n",
    "plt.plot(cxx.mean(axis=0))\n",
    "plt.figure()\n",
    "plt.plot(cxy.mean(axis=0))\n",
    "plt.figure()\n",
    "plt.plot(cyy.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running treecorr on the grid of ellipticities\n",
    "To run this you'll need to have TreeCorr installed.  Lots of info here, including a link to a notebook with examples\n",
    "https://github.com/rmjarvis/TreeCorr\n",
    "\n",
    "We can run this over the superpixel grid of e1, e2 we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import treecorr\n",
    "import numpy as np\n",
    "\n",
    "# Read in e1, e2 from file Jahmour made\n",
    "# file = open('ellip_data_chris_20829vis_fid1_32x32.dat')\n",
    "file = open(\"anna_20829_vis_april_18.dat\")\n",
    "a = np.genfromtxt(file, delimiter=\" \", dtype=\"str\")\n",
    "\n",
    "file.close()\n",
    "a = np.char.strip(a, \"[\")\n",
    "a = np.char.strip(a, \"]\")\n",
    "a = np.char.strip(a, \",\").astype(float)\n",
    "e1 = a[:, 0].copy()\n",
    "e2 = a[:, 1].copy()\n",
    "# x = a[:,3].copy() # Check which is x and which is y\n",
    "# y = a[:,4].copy()\n",
    "x = a[:, 2].copy()  # Check which is x and which is y\n",
    "y = a[:, 3].copy()\n",
    "# WFI detector pixel scale in arcseconds/pixel is 0.11, so one superpixel (32x32) is ~14 arcsec across\n",
    "x *= 0.11 * 128  # units from arcsec/superpixel to obtain x in arcsec\n",
    "y *= 0.11 * 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up and compute correlations with treecorr\n",
    "cat = treecorr.Catalog(ra=x, dec=y, ra_units=\"arcsec\", dec_units=\"arcsec\", g1=e1, g2=e2)\n",
    "# Remember that a single detector is about 7.5 arcmin on a side, so this sets a maximum scale\n",
    "gg = treecorr.GGCorrelation(min_sep=1.0, max_sep=9.5, bin_size=0.3, sep_units=\"arcmin\")\n",
    "gg.process(cat)\n",
    "xip = gg.xip  # The xi_plus correlation function\n",
    "xim = gg.xim\n",
    "err_xip = np.sqrt(gg.varxip)\n",
    "err_xim = np.sqrt(gg.varxim)\n",
    "npairs = gg.npairs\n",
    "wt = gg.weight  # There were no weights, so this will be the same as npairs\n",
    "r = np.exp(gg.meanlogr)\n",
    "print(npairs)\n",
    "print(wt)\n",
    "\n",
    "# Plotting\n",
    "plt.errorbar(r, xip, yerr=err_xip, fmt=\"ko\", label=\"xi+\")\n",
    "plt.errorbar(r, xim, yerr=err_xim, fmt=\"r^\", label=\"xi-\")\n",
    "plt.xlabel(\"separation (arcmin)\")\n",
    "plt.xscale(\"linear\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# This high amplitude might be a function of how the ellipticities were calculated from the covariance\n",
    "\n",
    "# Write out file to text\n",
    "savefile = open(\"xipm_20829.txt\")\n",
    "np.savetxt(savefile, np.array((r, xip, err_xip, xim, err_xim)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the non-linearity parameters we are getting from Paper III to Paper IV\n",
    "\n",
    "Both papers are using 4th order polynomials.\n",
    "\n",
    "Paper III used frames 1 to 10 to fit the polynomial. This is described around page 23.  Paper IV is using frames 1 to 16. As one can imagine that polynomials fit to different frames might differ substantially, Chris suggested comparing\n",
    "$$ \\sum_{\\nu}\\beta_{\\nu} g^{\\nu-1}S^{\\nu} = \\beta_{2} gS^{2}+\\beta_{3} g^{2}S^{3}+\\beta_{4} g^{3}S^{4}$$\n",
    "where $\\nu$ will run over 2, 3, 4, and this quantity has units of signal, or DN.\n",
    "\n",
    "Relevant Paper III values:\n",
    "\n",
    "|   |  SCA 20663 | SCA 20828  | SCA 20829  |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| charge per time slice (ke)  | 3.5055  | 3.0869  | 3.0515  |\n",
    "| gain (e/DN)  | 1.6232  | 1.6654   | 1.7285  |\n",
    "| $\\beta_{2}$g ($10^{6}\\textrm{DN}^{−1}$)  | 2.7899  | 2.1758  | 2.8147  |\n",
    "| $\\beta_{3}$g$^2$ ($10^{10} \\textrm{DN}^{−2}$)  | -0.8173 | -0.7621  | -1.0841  |\n",
    "| $\\beta_{4}$g$^3$ ($10^{15} \\textrm{DN}^{−3}$)  | 1.5245  | 1.6909  | 2.3025  |\n",
    "\n",
    "Relevant Paper IV values:\n",
    "\n",
    "|   |  SCA 20663 | SCA 20828  | SCA 20829  |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| charge per time slice (ke)  | 3.4918  | 3.0666  | 3.0376  |\n",
    "| gain (e/DN)  | 1.6264  | 1.6615   | 1.7357  |\n",
    "| $\\beta_{2}$g ($10^6\\textrm{DN}^{−1}$)  | 1.8884  | 1.3793  | 1.7637  |\n",
    "| $\\beta_{3}$g$^2$ ($10^{10} \\textrm{DN}^{−2}$)  | -0.2857 | -0.2354  | -0.4255  |\n",
    "| $\\beta_{4}$g$^3$ ($10^{15} \\textrm{DN}^{−3}$)  | 0.4966  | 0.5329  | 0.8553  |\n",
    "\n",
    "Equation 32 from Freudenburg, Givans et al. gives the relationship between the signal at a time slice and the charge.  Since Paper III used only up to frame 10, we can use the accumulated charge (the values from the table above multiplied by the accumulated time at frame 10) to determine the signal.\n",
    "\n",
    "Update: It makes the most sense to compare the output of the Equation 32 signal between Paper III and Paper IV, as what the typical reader might want to know is whether the mapping between the charge and the signal makes sense given the different set of $\\beta$ coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sum_comp(bc, S):\n",
    "    \"\"\"bc is an array of beta coefficients in the order beta2 x g, beta3 x g^2, beta4 x g^3\n",
    "    S is the signal at the given time frame\n",
    "    \"\"\"\n",
    "    return bc[0] * S + bc[1] * S**2 + bc[2] * S**3\n",
    "\n",
    "\n",
    "def charge_to_s(chargeperframe, bc, g, tframe):\n",
    "    \"\"\"bc is the same as in the prev function. charge is the charge per time slice, g is gain\n",
    "    t is the length of the time step, typically 2.75sec, and tframe is the frame number\"\"\"\n",
    "    Qtot = chargeperframe * (tframe - 1)\n",
    "    S = (1.0 / g) * (Qtot - (bc[0] / g) * Qtot**2 - (bc[1] / g**2) * Qtot**3 - (bc[2] / g**3) * Qtot**4)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with SCA 20663\n",
    "Q3 = 3.5055 * 1000  # e/time slice\n",
    "Q4 = 3.4918 * 1000  # e/time slice\n",
    "g3 = 1.6232  # e/DN\n",
    "g4 = 1.6264  # e/DN\n",
    "frame = 10\n",
    "beta_coef3 = np.array((2.7899e-6, -0.8173e-10, 1.5245e-15))  # DN**-1, DN**-2, DN**-3\n",
    "beta_coef4 = np.array((1.8884e-6, -0.2857e-10, 0.4966e-15))\n",
    "\n",
    "# Call the functions in the previous cell to compute the sum\n",
    "S_paper3 = charge_to_s(Q3, beta_coef3, g3, frame)\n",
    "sum_paper3 = sum_comp(beta_coef3, S_paper3)\n",
    "S_paper4 = charge_to_s(Q4, beta_coef4, g4, frame)\n",
    "sum_paper4 = sum_comp(beta_coef4, S_paper4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(S_paper3)\n",
    "print(S_paper4)\n",
    "print(\"Sum at frame %d from Paper 3: \" % frame, sum_paper3)\n",
    "print(\"Sum at frame %d from Paper 4: \" % frame, sum_paper4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to calculate the error on the above quantities.\n",
    "To propagate the errors on various quantities for a given function X(x$_1$,...,x$_n$), we can use\n",
    "$$\\sigma_X^2 = (\\frac{\\delta X}{\\delta x_1})^2 \\sigma_{x_1}^2 + ... + (\\frac{\\delta X}{\\delta x_n})^2 \\sigma_{x_n}^2 $$\n",
    "\n",
    "Relevant Paper III error on the mean values:\n",
    "\n",
    "|   |  SCA 20663 | SCA 20828  | SCA 20829  |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| err charge per time slice (ke)  | 0.00129  | 0.00120  | 0.00119  |\n",
    "| err gain (e/DN)  | 0.00147  | 0.0020   | 0.00141  |\n",
    "| err $\\beta_{2}$g ($10^{6}\\textrm{DN}^{−1}$)  | 0.0106  | 0.00745  | 0.00908  |\n",
    "| err $\\beta_{3}$g$^2$ ($10^{10} \\textrm{DN}^{−2}$)  | 0.00515 | 0.00420  | 0.00530  |\n",
    "| err $\\beta_{4}$g$^3$ ($10^{15} \\textrm{DN}^{−3}$)  | 0.00975  | 0.00947  | 0.0118  |\n",
    "\n",
    "Relevant Paper IV values:\n",
    "\n",
    "|   |  SCA 20663 | SCA 20828  | SCA 20829  |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| err charge per time slice (ke)  | 0.00135  | 0.00680  | 0.00104  |\n",
    "| err gain (e/DN)  | 0.00139  | 0.00412   | 0.00131  |\n",
    "| err $\\beta_{2}$g ($10^6\\textrm{DN}^{−1}$)  | 0.0071  | 0.00748  | 0.00590  |\n",
    "| err $\\beta_{3}$g$^2$ ($10^{10} \\textrm{DN}^{−2}$)  | 0.00244 | 0.00263  | 0.00207  |\n",
    "| err $\\beta_{4}$g$^3$ ($10^{15} \\textrm{DN}^{−3}$)  | 0.00347  | 0.0046  | 0.00280  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_sum_comp(bc, S, err_bc, err_S):\n",
    "    \"\"\"bc is an array of beta coefficients in the order beta2 x g, beta3 x g^2, beta4 x g^3\n",
    "    S is the signal at the given time frame\n",
    "    bc[0], bc[1], bc[2], and S will comprise the x_n for the purposes of error prop\n",
    "    \"\"\"\n",
    "    # bc[0] term\n",
    "    term1 = S**2 * err_bc[0] ** 2\n",
    "    term2 = S**4 * err_bc[1] ** 2\n",
    "    term3 = S**5 * err_bc[2] ** 2\n",
    "    term4 = (bc[0] + 2 * bc[1] * S + 3 * bc[2] * S**2) ** 2 * err_S\n",
    "    return np.sqrt(term1 + term2 + term3 + term4)\n",
    "\n",
    "\n",
    "def err_charge_to_s(chargeperframe, bc, g, tframe, err_chargeperframe, err_bc, err_g):\n",
    "    \"\"\"bc is the same as in the prev function. charge is the charge per time slice, g is gain\n",
    "    t is the length of the time step, typically 2.75sec, and tframe is the frame number\n",
    "    bc[0], bc[1], bc[2], Q, and g are the x_n for this function\"\"\"\n",
    "    Qtot = chargeperframe * (tframe - 1)\n",
    "    err_Qtot = err_chargeperframe * (tframe - 1)\n",
    "    term1 = (Qtot**2 / g) ** 2 * err_bc[0] ** 2\n",
    "    term2 = (Qtot**3 / g**3) ** 2 * err_bc[1] ** 2\n",
    "    term3 = (Qtot**4 / g**4) ** 2 * err_bc[2] ** 2\n",
    "    term4 = (\n",
    "        1.0 / g - 2 * bc[0] * Qtot / g**2 - 3 * bc[1] * Qtot**2 / g**3 - 4 * bc[2] * Qtot**3 / g**4\n",
    "    ) ** 2 * err_Qtot**2\n",
    "    term5 = (\n",
    "        (-1.0 / g**2)\n",
    "        + (2 * bc[0] * Qtot**2 / g**3)\n",
    "        + (3 * bc[1] * Qtot**3 / g**4)\n",
    "        + (4 * bc[2] * Qtot**4 / g**5) ** 2 * err_g**2\n",
    "    )\n",
    "    return np.sqrt(term1 + term2 + term3 + term4 + term5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the errors\n",
    "err_Q3 = 0.00129 * 1000  # e/time slice\n",
    "err_Q4 = 0.00135 * 1000  # e/time slice\n",
    "err_g3 = 0.00147  # e/DN\n",
    "err_g4 = 0.00139  # e/DN\n",
    "err_beta_coef3 = np.array((0.0106e-6, 0.00515e-10, 0.00975e-15))  # DN**-1, DN**-2, DN**-3\n",
    "err_beta_coef4 = np.array((0.0071e-6, 0.00244e-10, 0.00347e-15))\n",
    "\n",
    "# Call the functions in the previous cell to compute the sum\n",
    "err_S_paper3 = err_charge_to_s(Q3, beta_coef3, g3, frame, err_Q3, err_beta_coef3, err_g3)\n",
    "err_sum_paper3 = err_sum_comp(beta_coef3, S_paper3, err_beta_coef3, err_S_paper3)\n",
    "err_S_paper4 = err_charge_to_s(Q4, beta_coef4, g4, frame, err_Q4, err_beta_coef4, err_g4)\n",
    "err_sum_paper4 = err_sum_comp(beta_coef4, S_paper4, err_beta_coef4, err_S_paper4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Sum at frame %d from Paper 3: %f +/- %f: \"%(frame,sum_paper3,err_sum_paper3))\n",
    "# print(\"Sum at frame %d from Paper 4: %f +/- %f: \"%(frame,sum_paper4,err_sum_paper4))\n",
    "print(\"Signal at frame %d from Paper 3: %f +/- %f: \" % (frame, S_paper3, err_S_paper3))\n",
    "print(\"Signal at frame %d from Paper 4: %f +/- %f: \" % (frame, S_paper4, err_S_paper4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
